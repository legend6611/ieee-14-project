{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "19jvWsqTF9VPeYoDDjVIUk0YGcufDwvk4",
      "authorship_tag": "ABX9TyMkSgoVbjNh1PGfL52qidCI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/legend6611/ieee-14-project/blob/main/faster%20rcnn%20model\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LkXp9tigFTuo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import cv2\n",
        "import torch\n",
        "from torch.utils import data\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/object_detect_gtsdb'\n",
        "files = os.listdir(folder_path)\n",
        "print(files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ1kSlImI9P9",
        "outputId": "4e44e9df-c82d-4979-c0cc-bac772a92e02"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "['gt.txt', 'imagesf', '__pycache__', 'util', 'my_datasets', 'my_utils.py', 'hub', 'coco_utils.py', 'final_training_results.pkl', 'final_model.pth', 'engine.py', 'label_mapping.pkl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = np.genfromtxt('/content/drive/MyDrive/object_detect_gtsdb/gt.txt',delimiter =';', dtype= None,encoding=None)\n",
        "\n",
        "#Creating a dictionary with image names as key and annotations as value\n",
        "dic ={}\n",
        "for i in range (0,len(txt)):\n",
        "    #Image name is first element of annotation file\n",
        "    img_name = txt[i][0]\n",
        "    # 4 Coordinates\n",
        "    target = [txt[i][1],txt[i][2],txt[i][3],txt[i][4],txt[i][5]]\n",
        "    #Last element is the class number\n",
        "    clas = txt[i][-1]\n",
        "    #If multiple objects, store coordinates and classes as list of lists\n",
        "    if(img_name in dic):\n",
        "        dic[img_name].append(target)\n",
        "    else:\n",
        "        dic[img_name] = [target]\n",
        "print(dic['00001.ppm'])\n",
        "print(\"Number of Images: \" + str(len(dic)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijJAAUssKtNe",
        "outputId": "1c30cdbc-c50c-437f-bc93-cef94bddd6e8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[np.int64(983), np.int64(388), np.int64(1024), np.int64(432), np.int64(40)], [np.int64(386), np.int64(494), np.int64(442), np.int64(552), np.int64(38)], [np.int64(973), np.int64(335), np.int64(1031), np.int64(390), np.int64(13)]]\n",
            "Number of Images: 506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dic['00001.ppm']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrpb3ui1M9NX",
        "outputId": "53fb1838-fa4e-4fca-9c7f-6127eb9441fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[np.int64(983), np.int64(388), np.int64(1024), np.int64(432), np.int64(40)],\n",
              " [np.int64(386), np.int64(494), np.int64(442), np.int64(552), np.int64(38)],\n",
              " [np.int64(973), np.int64(335), np.int64(1031), np.int64(390), np.int64(13)]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cls_lst = {}\n",
        "\n",
        "for i in dic:\n",
        "    for j in dic[i][:]:\n",
        "        #print(len(dic[i]))\n",
        "        for k in range(len(dic[i])):\n",
        "            clss = dic[i][:][k][-1]\n",
        "            if clss in cls_lst:\n",
        "                cls_lst[clss] += 1\n",
        "            else:\n",
        "                cls_lst[clss] = 1\n",
        "\n",
        "print(cls_lst)\n",
        "\n",
        "xx = []\n",
        "yy = []\n",
        "for i in cls_lst:\n",
        "    xx.append(str(i))\n",
        "    yy.append(cls_lst[i])\n",
        "\n",
        "x_pos = [i for i, _ in enumerate(xx)]\n",
        "\n",
        "plt.bar(x_pos, yy, color='green')\n",
        "plt.xlabel(\"Class Number\")\n",
        "plt.ylabel(\"Number of Examples\")\n",
        "plt.title(\"GTSDB\")\n",
        "#plt.figure(figsize=(30,30))\n",
        "plt.xticks(x_pos, xx)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "Lj8NZjlIRdLv",
        "outputId": "51d5041b-f41d-4eca-98fd-01ca0d0246b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{np.int64(11): 39, np.int64(40): 17, np.int64(38): 115, np.int64(13): 119, np.int64(39): 10, np.int64(4): 70, np.int64(9): 67, np.int64(21): 10, np.int64(2): 111, np.int64(12): 101, np.int64(1): 84, np.int64(25): 34, np.int64(30): 29, np.int64(23): 31, np.int64(27): 6, np.int64(35): 30, np.int64(15): 18, np.int64(33): 31, np.int64(28): 22, np.int64(18): 53, np.int64(36): 18, np.int64(26): 23, np.int64(37): 2, np.int64(34): 24, np.int64(0): 7, np.int64(24): 6, np.int64(14): 49, np.int64(20): 24, np.int64(29): 6, np.int64(6): 33, np.int64(10): 167, np.int64(8): 135, np.int64(5): 69, np.int64(16): 11, np.int64(19): 3, np.int64(17): 75, np.int64(3): 35, np.int64(7): 69, np.int64(41): 13, np.int64(31): 2, np.int64(22): 22, np.int64(42): 15, np.int64(32): 5}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/object_detect_gtsdb')\n"
      ],
      "metadata": {
        "id": "-3fid7UJckyO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import pickle\n",
        "\n",
        "def analyze_labels(dic):\n",
        "    \"\"\"\n",
        "    Analyze all labels in the dataset to understand the label distribution\n",
        "    \"\"\"\n",
        "    all_labels = []\n",
        "\n",
        "    for key, objects in dic.items():\n",
        "        for obj in objects:\n",
        "            label = int(obj[-1])  # Assuming label is the last element\n",
        "            all_labels.append(label)\n",
        "\n",
        "    unique_labels = sorted(set(all_labels))\n",
        "    label_counts = {label: all_labels.count(label) for label in unique_labels}\n",
        "\n",
        "    print(f\"Label Analysis:\")\n",
        "    print(f\"Total objects: {len(all_labels)}\")\n",
        "    print(f\"Unique labels: {len(unique_labels)}\")\n",
        "    print(f\"Label range: {min(unique_labels)} to {max(unique_labels)}\")\n",
        "    print(f\"Labels: {unique_labels}\")\n",
        "    print(f\"Label distribution: {label_counts}\")\n",
        "\n",
        "    return unique_labels, label_counts\n",
        "\n",
        "def create_label_mapping(unique_labels, start_from=1):\n",
        "    \"\"\"\n",
        "    Create mapping from original labels to consecutive labels starting from start_from\n",
        "    For object detection, labels typically start from 1 (0 is reserved for background)\n",
        "    \"\"\"\n",
        "    label_mapping = {}\n",
        "    reverse_mapping = {}\n",
        "\n",
        "    for i, original_label in enumerate(sorted(unique_labels)):\n",
        "        new_label = i + start_from\n",
        "        label_mapping[original_label] = new_label\n",
        "        reverse_mapping[new_label] = original_label\n",
        "\n",
        "    print(f\"\\nLabel Mapping (original -> new):\")\n",
        "    for orig, new in label_mapping.items():\n",
        "        print(f\"  {orig} -> {new}\")\n",
        "\n",
        "    return label_mapping, reverse_mapping\n",
        "\n",
        "class myDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transforms=None, min_box_size=10, label_mapping=None):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.min_box_size = min_box_size\n",
        "        self.label_mapping = label_mapping or {}  # Mapping from original labels to new labels\n",
        "        # load all image files, sorting them to ensure that they are aligned\n",
        "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"imagesf\"))))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load image path\n",
        "        img_path = os.path.join(self.root, \"imagesf\", self.imgs[idx])\n",
        "        # Load image as PIL\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        img_width, img_height = img.size\n",
        "\n",
        "        # Get objects in the image\n",
        "        key = self.imgs[idx]\n",
        "\n",
        "        # Check if key exists in dic\n",
        "        if key not in dic:\n",
        "            print(f\"Warning: Key '{key}' not found in annotations. Skipping...\")\n",
        "            target = {\n",
        "                \"boxes\": torch.zeros((0, 4), dtype=torch.float32),\n",
        "                \"labels\": torch.zeros(0, dtype=torch.int64),\n",
        "                \"image_id\": idx,\n",
        "                \"area\": torch.zeros(0, dtype=torch.float32),\n",
        "                \"iscrowd\": torch.zeros(0, dtype=torch.int64)\n",
        "            }\n",
        "            if self.transforms is not None:\n",
        "                img = self.transforms(img)\n",
        "            return img, target\n",
        "\n",
        "        objects = dic[key]\n",
        "\n",
        "        # Get bounding box coordinates for each object in image\n",
        "        valid_boxes = []\n",
        "        valid_labels = []\n",
        "\n",
        "        for obj in objects:\n",
        "            original_label = int(obj[-1])\n",
        "\n",
        "            # Map label if mapping is provided\n",
        "            if self.label_mapping:\n",
        "                if original_label in self.label_mapping:\n",
        "                    label = self.label_mapping[original_label]\n",
        "                else:\n",
        "                    print(f\"Warning: Unknown label {original_label} in {key}, skipping object\")\n",
        "                    continue\n",
        "            else:\n",
        "                label = original_label\n",
        "\n",
        "            # Get bounding box coordinates\n",
        "            xmin = float(obj[0])\n",
        "            ymin = float(obj[1])\n",
        "            xmax = float(obj[2])\n",
        "            ymax = float(obj[3])\n",
        "\n",
        "            # Fix coordinate order if necessary\n",
        "            if xmin > xmax:\n",
        "                xmin, xmax = xmax, xmin\n",
        "\n",
        "            if ymin > ymax:\n",
        "                ymin, ymax = ymax, ymin\n",
        "\n",
        "            # Clamp coordinates to image boundaries\n",
        "            xmin = max(0, min(xmin, img_width - 1))\n",
        "            ymin = max(0, min(ymin, img_height - 1))\n",
        "            xmax = max(xmin + 1, min(xmax, img_width))\n",
        "            ymax = max(ymin + 1, min(ymax, img_height))\n",
        "\n",
        "            # Check if box is valid\n",
        "            width = xmax - xmin\n",
        "            height = ymax - ymin\n",
        "\n",
        "            if width >= self.min_box_size and height >= self.min_box_size:\n",
        "                valid_boxes.append([xmin, ymin, xmax, ymax])\n",
        "                valid_labels.append(label)\n",
        "\n",
        "        # Handle case where no valid boxes remain\n",
        "        if len(valid_boxes) == 0:\n",
        "            target = {\n",
        "                \"boxes\": torch.zeros((0, 4), dtype=torch.float32),\n",
        "                \"labels\": torch.zeros(0, dtype=torch.int64),\n",
        "                \"image_id\": idx,\n",
        "                \"area\": torch.zeros(0, dtype=torch.float32),\n",
        "                \"iscrowd\": torch.zeros(0, dtype=torch.int64)\n",
        "            }\n",
        "            if self.transforms is not None:\n",
        "                img = self.transforms(img)\n",
        "            return img, target\n",
        "\n",
        "        boxes = torch.as_tensor(valid_boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(valid_labels, dtype=torch.int64)\n",
        "\n",
        "        image_id = idx\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        iscrowd = torch.zeros((len(valid_boxes),), dtype=torch.int64)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "def get_model_with_correct_classes(num_classes):\n",
        "    \"\"\"\n",
        "    Create a model with the correct number of output classes\n",
        "    \"\"\"\n",
        "    import torchvision\n",
        "    from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "    # Load pre-trained model\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "    # Get number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "    # Replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Usage example:\n",
        "def setup_dataset_and_model():\n",
        "    \"\"\"\n",
        "    Complete setup function to analyze labels and create proper dataset/model\n",
        "    \"\"\"\n",
        "    # 1. Analyze labels in your data\n",
        "    unique_labels, label_counts = analyze_labels(dic)\n",
        "\n",
        "    # 2. Create label mapping (starting from 1, as 0 is background in object detection)\n",
        "    label_mapping, reverse_mapping = create_label_mapping(unique_labels, start_from=1)\n",
        "\n",
        "    # 3. Calculate number of classes (including background class 0)\n",
        "    num_classes = len(unique_labels) + 1  # +1 for background\n",
        "    print(f\"\\nModel will be created with {num_classes} classes\")\n",
        "\n",
        "    # 4. Create model with correct number of classes\n",
        "    model = get_model_with_correct_classes(num_classes)\n",
        "\n",
        "    # 5. Create dataset with label mapping\n",
        "    transforms = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    train_dataset = myDataset('your_root_path', transforms=transforms, label_mapping=label_mapping)\n",
        "\n",
        "    return model, train_dataset, label_mapping, reverse_mapping, num_classes\n",
        "\n",
        "# Save label mapping for later use\n",
        "def save_label_mapping(label_mapping, reverse_mapping, filename=\"label_mapping.pkl\"):\n",
        "    mapping_data = {\n",
        "        'label_mapping': label_mapping,  # original -> new\n",
        "        'reverse_mapping': reverse_mapping,  # new -> original\n",
        "        'num_classes': len(label_mapping) + 1  # +1 for background\n",
        "    }\n",
        "\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(mapping_data, f)\n",
        "\n",
        "    print(f\"Label mapping saved to {filename}\")\n",
        "    return mapping_data"
      ],
      "metadata": {
        "id": "e0RvZK3SLQY5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic = {}\n",
        "root = r'/content/drive/MyDrive/object_detect_gtsdb'\n",
        "with open(os.path.join(root, \"gt.txt\")) as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split(';')\n",
        "        fname = parts[0]  # '00000.ppm'\n",
        "        class_id = int(parts[1])\n",
        "        bbox = list(map(int, parts[2:]))  # [x1, y1, x2, y2]\n",
        "\n",
        "        if fname not in dic:\n",
        "            dic[fname] = []\n",
        "\n",
        "        dic[fname].append([*bbox, class_id])"
      ],
      "metadata": {
        "id": "kdzIhoCNN1UA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWrAVfm8SyRs",
        "outputId": "cfde31d4-e396-4cba-bc89-470419c1eb9f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LBf5xmEmS8BV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Go to your working directory\n",
        "%cd /content/drive/MyDrive/object_detect_gtsdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IGNBYxdS0JM",
        "outputId": "969f71cd-4ed7-4cec-a672-81e36917d425"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/object_detect_gtsdb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Add the parent folder to Python path\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/object_detect_gtsdb')"
      ],
      "metadata": {
        "id": "WgjQYUvYS9RM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir('./util'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AWkQ5S9TEF_",
        "outputId": "873909c7-9c5b-425f-aae3-a54a6e60324c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__init__.py', 'box_ops.py', 'plot_utils.py', 'misc.py', '__pycache__']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from util import misc\n"
      ],
      "metadata": {
        "id": "ztsxgt9nTqJl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/object_detect_gtsdb')\n",
        "%cd /content/drive/MyDrive/object_detect_gtsdb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJFdT0erSMGh",
        "outputId": "85700f7b-d2a3-45af-9c30-662c63b68dba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/object_detect_gtsdb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Ensure util is a package\n",
        "!touch util/__init__.py\n"
      ],
      "metadata": {
        "id": "NpllXaj9QHoQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8bFtYbLUg7S",
        "outputId": "1de2ced6-bfda-4e96-f67b-017cb1b9a596"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'datasets': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/object_detect_gtsdb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTchte9MUlKK",
        "outputId": "26e1575a-063b-4c04-b33f-aa432a2094e0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/object_detect_gtsdb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/drive/MyDrive/object_detect_gtsdb')\n"
      ],
      "metadata": {
        "id": "nynHzSDwUphr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls my_datasets\n",
        "print(sys.path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWSUEzg7YdK0",
        "outputId": "a938eba7-e074-40e0-95a4-dc5ff0fb70d4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coco_eval.py\t  coco.py      panoptic_eval.py  transforms.py\n",
            "coco_panoptic.py  __init__.py  __pycache__\n",
            "['/content/drive/MyDrive/object_detect_gtsdb', '/content', '/env/python', '/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '', '/usr/local/lib/python3.11/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.11/dist-packages/IPython/extensions', '/root/.ipython', '/usr/local/lib/python3.11/dist-packages/setuptools/_vendor', '/tmp/tmpg1pi156j', '/content/drive/MyDrive/object_detect_gtsdb', '/content/drive/MyDrive/object_detect_gtsdb', '/content/drive/MyDrive/object_detect_gtsdb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find . -name coco_eval.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GQxoUOHYqe_",
        "outputId": "e9051d4e-8c92-4d49-fd3b-00fec42c5da4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./my_datasets/coco_eval.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('/content/drive/MyDrive/object_detect_gtsdb')\n"
      ],
      "metadata": {
        "id": "qmzP2BfelkA0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from my_datasets.coco_eval import CocoEvaluator\n",
        "\n"
      ],
      "metadata": {
        "id": "IL8AxL3Hln9-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/object_detect_gtsdb')\n",
        "from my_datasets import coco_eval"
      ],
      "metadata": {
        "id": "vezw7e0fUMcQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/object_detect_gtsdb/my_datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQBVKO4AZNQa",
        "outputId": "24f63de0-fdf2-46ed-b2cb-6300e403851b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coco_eval.py\t  coco.py      panoptic_eval.py  transforms.py\n",
            "coco_panoptic.py  __init__.py  __pycache__\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/object_detect_gtsdb')\n"
      ],
      "metadata": {
        "id": "2MDUGtU-SqQ0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import engine"
      ],
      "metadata": {
        "id": "bzvBtVwAkq6h"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/object_detect_gtsdb')  # Don't include a comma or parentheses here\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/object_detect_gtsdb')\n",
        "print(sys.path[-1])  # Confirm it's a string\n",
        "\n",
        "import os\n",
        "print(os.path.isfile('/content/drive/MyDrive/object_detect_gtsdb/my_utils.py'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc5QKeqsbHvJ",
        "outputId": "dd81bec7-6a03-4bb9-83da-7f25dfc73a79"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/object_detect_gtsdb\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 15 /content/drive/MyDrive/object_detect_gtsdb/my_utils.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4r6PlhHgv81",
        "outputId": "92729b5d-6cfe-472c-a87a-8f66fcd7a416"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import datetime\n",
            "import errno\n",
            "import os\n",
            "import time\n",
            "from collections import defaultdict, deque\n",
            "\n",
            "import torch\n",
            "import torch.distributed as dist\n",
            "\n",
            "\n",
            "class SmoothedValue:\n",
            "    \"\"\"Track a series of values and provide access to smoothed values over a\n",
            "    window or the global series average.\n",
            "    \"\"\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/object_detect_gtsdb')\n",
        "\n",
        "# Now you can import engine.py like this:\n",
        "import engine"
      ],
      "metadata": {
        "id": "E_DFMTSrP6rW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mpIP8gbBQp0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import my_utils\n",
        "from torchvision import transforms as T\n",
        "from engine import train_one_epoch, evaluate\n",
        "# utils, transforms, engine were just downloadedUtils.py,transforms.py,engine.py\n",
        "\n",
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    # converts the image, a PIL image, into a PyTorch Tensor\n",
        "    transforms.append(T.ToTensor())\n",
        "    if train:\n",
        "        # during training, randomly flip the training images\n",
        "        # and ground-truth for data augmentation\n",
        "        # 50% chance of flipping horizontally\n",
        "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "\n",
        "    return T.Compose(transforms)"
      ],
      "metadata": {
        "id": "S1J6A6mROzj4"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/object_detect_gtsdb')\n"
      ],
      "metadata": {
        "id": "QI_3B_Okcar0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import my_utils"
      ],
      "metadata": {
        "id": "EUhKGPSscfbJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from engine import train_one_epoch, evaluate\n",
        "import my_utils\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "os.environ['TORCH_HOME'] = './'\n",
        "\n",
        "root = r'/content/drive/MyDrive/object_detect_gtsdb'\n",
        "\n",
        "# Train on the GPU if available else CPU.\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# 44 classes = 43 + background\n",
        "num_classes = 44\n",
        "#Send the data to the myDataset class (Apply transformations, Get bbox, labels, objects)\n",
        "dataset = myDataset(root, get_transform(train=True))\n",
        "dataset_test = myDataset(root, get_transform(train=False))\n",
        "\n",
        "# split the dataset in train and test set\n",
        "# My dataset has 506 images, almost training validation 4:1\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "dataset = torch.utils.data.Subset(dataset, indices[:-100])\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[-100:])\n",
        "\n",
        "# define training and validation data loaders\n",
        "#collate_fn returns tuples of images and image annotations for every iteration.\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=2, shuffle=True, # num_workers=4,\n",
        "    collate_fn=my_utils.collate_fn)\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test, batch_size=2, shuffle=False, # num_workers=4,\n",
        "    collate_fn=my_utils.collate_fn)\n",
        "\n",
        "# Define model\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, progress=True, num_classes=num_classes, pretrained_backbone=True)\n",
        "# OR model = get_object_detection_model(num_classes)\n",
        "#model = torch.load('./train150.pkl')\n",
        "\n",
        "#Use specific GPUs:\n",
        "#Remove this line if not necessary.\n",
        "\n",
        "# Move the model to device\n",
        "model.to(device)\n",
        "\n",
        "print(\"Model loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezDtIqe6ax7Z",
        "outputId": "8ba4fc78-3cfd-442b-b188-19904c13009e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained_backbone' is deprecated since 0.13 and may be removed in the future, please use 'weights_backbone' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights_backbone' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights_backbone=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights_backbone=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "import pickle\n",
        "\n",
        "# Step 1: Analyze your labels and create mapping\n",
        "print(\"Step 1: Analyzing labels...\")\n",
        "unique_labels, label_counts = analyze_labels(dic)\n",
        "\n",
        "# Step 2: Create label mapping\n",
        "print(\"\\nStep 2: Creating label mapping...\")\n",
        "label_mapping, reverse_mapping = create_label_mapping(unique_labels, start_from=1)\n",
        "\n",
        "# Step 3: Calculate number of classes\n",
        "num_classes = len(unique_labels) + 1  # +1 for background\n",
        "print(f\"\\nStep 3: Number of classes (including background): {num_classes}\")\n",
        "\n",
        "# Step 4: Create model with correct number of classes\n",
        "print(f\"\\nStep 4: Creating model...\")\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "# Move model to device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Step 5: Create datasets with label mapping\n",
        "print(f\"\\nStep 5: Creating datasets...\")\n",
        "def get_transforms(train=True):\n",
        "    transforms = [T.ToTensor()]\n",
        "    if train:\n",
        "        # Add data augmentation for training\n",
        "        transforms.append(T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1))\n",
        "    transforms.append(T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]))\n",
        "    return T.Compose(transforms)\n",
        "\n",
        "# Update your root path here\n",
        "root_path = r'/content/drive/MyDrive/object_detect_gtsdb'\n",
        "\n",
        "train_dataset = myDataset(root_path,\n",
        "                         transforms=get_transforms(train=True),\n",
        "                         label_mapping=label_mapping)\n",
        "\n",
        "test_dataset = myDataset(root_path,\n",
        "                        transforms=get_transforms(train=False),\n",
        "                        label_mapping=label_mapping)\n",
        "\n",
        "# Step 6: Create data loaders\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                         batch_size=4,\n",
        "                         shuffle=True,\n",
        "                         collate_fn=collate_fn,\n",
        "                         num_workers=0)  # Set to 0 if having issues with multiprocessing\n",
        "\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                        batch_size=1,\n",
        "                        shuffle=False,\n",
        "                        collate_fn=collate_fn,\n",
        "                        num_workers=0)\n",
        "\n",
        "# Step 7: Setup training\n",
        "print(f\"\\nStep 7: Setting up training...\")\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.0005, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=2)\n",
        "\n",
        "# Step 8: Save label mapping for future use\n",
        "save_label_mapping(label_mapping, reverse_mapping, \"label_mapping.pkl\")\n",
        "\n",
        "print(f\"\\nSetup complete!\")\n",
        "print(f\"- Original labels: {unique_labels}\")\n",
        "print(f\"- Mapped labels: {list(range(1, num_classes))}\")\n",
        "print(f\"- Total classes (including background): {num_classes}\")\n",
        "print(f\"- Training samples: {len(train_dataset)}\")\n",
        "print(f\"- Test samples: {len(test_dataset)}\")\n",
        "\n",
        "# Step 9: Test the data loader\n",
        "print(f\"\\nStep 9: Testing data loader...\")\n",
        "try:\n",
        "    images, targets = next(iter(train_loader))\n",
        "    print(f\" Data loader working correctly!\")\n",
        "    print(f\"  Batch size: {len(images)}\")\n",
        "    if len(targets) > 0 and len(targets[0]['labels']) > 0:\n",
        "        print(f\"  Sample labels in batch: {targets[0]['labels'].tolist()}\")\n",
        "except Exception as e:\n",
        "    print(f\" Data loader error: {e}\")\n",
        "\n",
        "# Now you can use train_loader and test_loader for training\n",
        "data_loader = train_loader\n",
        "data_loader_test = test_loader\n",
        "\n",
        "print(f\"\\nYou can now start training with:\")\n",
        "print(f\"- model: {type(model).__name__}\")\n",
        "print(f\"- data_loader: {len(data_loader)} batches\")\n",
        "print(f\"- data_loader_test: {len(data_loader_test)} batches\")\n",
        "print(f\"- device: {device}\")\n",
        "\n",
        "# Your training loop can now proceed...\n",
        "# from engine import train_one_epoch, evaluate\n",
        "# metrics = train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMSCkN1KiHv7",
        "outputId": "39ab7657-60ab-43f4-e570-ab6564d6ed0b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Analyzing labels...\n",
            "Label Analysis:\n",
            "Total objects: 852\n",
            "Unique labels: 608\n",
            "Label range: 22 to 1305\n",
            "Labels: [22, 23, 27, 28, 29, 46, 53, 55, 56, 57, 58, 61, 69, 86, 91, 98, 99, 100, 101, 102, 107, 109, 110, 112, 113, 116, 120, 122, 124, 128, 138, 142, 148, 150, 157, 161, 163, 164, 166, 167, 172, 175, 178, 180, 183, 185, 186, 187, 192, 198, 201, 203, 204, 206, 209, 212, 213, 218, 224, 229, 230, 233, 235, 236, 237, 239, 240, 241, 242, 243, 244, 247, 248, 249, 252, 253, 256, 257, 259, 260, 262, 264, 266, 267, 271, 273, 275, 278, 283, 284, 285, 288, 290, 291, 293, 294, 296, 297, 298, 302, 306, 307, 310, 311, 312, 314, 315, 316, 318, 323, 325, 327, 330, 335, 338, 339, 341, 344, 346, 350, 351, 353, 354, 355, 358, 359, 361, 365, 366, 367, 369, 377, 378, 379, 380, 381, 382, 383, 386, 389, 391, 392, 394, 396, 398, 401, 403, 407, 409, 410, 411, 412, 413, 420, 421, 423, 425, 430, 432, 438, 439, 440, 442, 445, 446, 451, 453, 454, 455, 456, 457, 458, 460, 461, 463, 467, 470, 471, 474, 475, 477, 483, 484, 486, 490, 491, 492, 494, 496, 500, 502, 504, 505, 507, 509, 510, 511, 514, 517, 518, 519, 520, 521, 527, 528, 532, 533, 534, 537, 538, 544, 549, 551, 553, 555, 558, 568, 569, 575, 579, 581, 584, 589, 593, 594, 597, 599, 601, 602, 603, 605, 610, 616, 617, 625, 627, 631, 634, 638, 644, 646, 648, 650, 655, 656, 657, 658, 662, 667, 668, 670, 671, 675, 677, 678, 680, 681, 683, 686, 689, 692, 693, 695, 696, 698, 699, 700, 702, 703, 705, 707, 708, 710, 711, 712, 713, 717, 718, 720, 721, 723, 724, 726, 727, 728, 729, 730, 731, 732, 734, 737, 742, 744, 745, 746, 750, 752, 753, 755, 756, 758, 760, 762, 763, 765, 766, 767, 769, 770, 771, 772, 774, 775, 779, 780, 782, 783, 784, 785, 786, 788, 789, 790, 792, 793, 794, 795, 798, 799, 800, 801, 802, 805, 808, 812, 813, 814, 815, 816, 817, 819, 822, 823, 824, 825, 826, 827, 828, 829, 831, 833, 834, 835, 836, 838, 839, 840, 841, 842, 843, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 863, 865, 866, 867, 868, 869, 870, 872, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 890, 891, 892, 893, 894, 895, 898, 900, 901, 902, 903, 904, 906, 907, 908, 909, 910, 912, 913, 915, 916, 921, 922, 923, 925, 926, 929, 932, 933, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 949, 950, 951, 952, 953, 956, 958, 962, 964, 965, 966, 967, 968, 969, 971, 972, 973, 974, 975, 976, 977, 979, 980, 982, 983, 984, 985, 988, 989, 990, 993, 994, 995, 997, 998, 999, 1000, 1002, 1008, 1009, 1010, 1011, 1015, 1017, 1019, 1021, 1025, 1028, 1032, 1036, 1038, 1039, 1040, 1042, 1043, 1045, 1046, 1047, 1048, 1050, 1051, 1052, 1054, 1055, 1056, 1062, 1063, 1064, 1071, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1089, 1090, 1091, 1092, 1094, 1095, 1097, 1101, 1104, 1105, 1110, 1111, 1113, 1117, 1120, 1122, 1123, 1125, 1127, 1128, 1129, 1131, 1132, 1133, 1135, 1138, 1139, 1140, 1141, 1143, 1144, 1146, 1147, 1150, 1151, 1152, 1156, 1159, 1166, 1168, 1169, 1172, 1173, 1177, 1182, 1185, 1186, 1193, 1194, 1195, 1196, 1199, 1201, 1202, 1205, 1206, 1209, 1211, 1212, 1213, 1214, 1215, 1219, 1220, 1223, 1224, 1226, 1227, 1228, 1229, 1231, 1233, 1236, 1237, 1238, 1241, 1242, 1243, 1244, 1245, 1249, 1255, 1260, 1264, 1267, 1271, 1273, 1274, 1282, 1285, 1287, 1294, 1295, 1302, 1305]\n",
            "Label distribution: {22: 2, 23: 1, 27: 1, 28: 1, 29: 1, 46: 1, 53: 1, 55: 1, 56: 1, 57: 1, 58: 1, 61: 1, 69: 1, 86: 1, 91: 1, 98: 1, 99: 1, 100: 1, 101: 1, 102: 1, 107: 1, 109: 1, 110: 2, 112: 1, 113: 1, 116: 2, 120: 1, 122: 1, 124: 1, 128: 1, 138: 1, 142: 1, 148: 1, 150: 1, 157: 1, 161: 1, 163: 1, 164: 1, 166: 1, 167: 1, 172: 1, 175: 1, 178: 1, 180: 1, 183: 1, 185: 2, 186: 1, 187: 1, 192: 1, 198: 1, 201: 1, 203: 1, 204: 1, 206: 1, 209: 1, 212: 1, 213: 2, 218: 1, 224: 1, 229: 1, 230: 2, 233: 1, 235: 1, 236: 1, 237: 1, 239: 1, 240: 1, 241: 1, 242: 1, 243: 1, 244: 1, 247: 2, 248: 1, 249: 2, 252: 1, 253: 1, 256: 1, 257: 2, 259: 1, 260: 1, 262: 1, 264: 1, 266: 1, 267: 1, 271: 2, 273: 1, 275: 1, 278: 1, 283: 1, 284: 1, 285: 2, 288: 1, 290: 1, 291: 1, 293: 1, 294: 1, 296: 1, 297: 1, 298: 1, 302: 2, 306: 1, 307: 1, 310: 1, 311: 1, 312: 1, 314: 2, 315: 1, 316: 2, 318: 1, 323: 1, 325: 3, 327: 1, 330: 1, 335: 1, 338: 1, 339: 1, 341: 1, 344: 1, 346: 1, 350: 1, 351: 1, 353: 1, 354: 1, 355: 1, 358: 1, 359: 1, 361: 1, 365: 1, 366: 1, 367: 1, 369: 2, 377: 1, 378: 1, 379: 3, 380: 1, 381: 1, 382: 2, 383: 2, 386: 1, 389: 1, 391: 1, 392: 1, 394: 1, 396: 1, 398: 1, 401: 1, 403: 1, 407: 1, 409: 1, 410: 2, 411: 1, 412: 1, 413: 2, 420: 2, 421: 1, 423: 1, 425: 3, 430: 2, 432: 1, 438: 1, 439: 1, 440: 1, 442: 1, 445: 1, 446: 1, 451: 1, 453: 1, 454: 1, 455: 3, 456: 2, 457: 1, 458: 1, 460: 2, 461: 1, 463: 1, 467: 1, 470: 1, 471: 1, 474: 2, 475: 1, 477: 2, 483: 1, 484: 1, 486: 1, 490: 1, 491: 1, 492: 1, 494: 1, 496: 1, 500: 1, 502: 1, 504: 2, 505: 2, 507: 1, 509: 3, 510: 1, 511: 2, 514: 2, 517: 2, 518: 1, 519: 2, 520: 2, 521: 1, 527: 1, 528: 1, 532: 1, 533: 1, 534: 1, 537: 1, 538: 1, 544: 1, 549: 1, 551: 2, 553: 1, 555: 2, 558: 1, 568: 2, 569: 2, 575: 1, 579: 1, 581: 1, 584: 1, 589: 1, 593: 1, 594: 1, 597: 1, 599: 1, 601: 1, 602: 1, 603: 1, 605: 1, 610: 2, 616: 1, 617: 1, 625: 1, 627: 1, 631: 1, 634: 1, 638: 1, 644: 1, 646: 1, 648: 1, 650: 1, 655: 1, 656: 1, 657: 2, 658: 1, 662: 1, 667: 2, 668: 1, 670: 1, 671: 1, 675: 1, 677: 1, 678: 3, 680: 1, 681: 1, 683: 1, 686: 1, 689: 1, 692: 1, 693: 3, 695: 2, 696: 1, 698: 1, 699: 1, 700: 1, 702: 1, 703: 1, 705: 1, 707: 2, 708: 1, 710: 1, 711: 1, 712: 2, 713: 2, 717: 1, 718: 5, 720: 2, 721: 1, 723: 2, 724: 1, 726: 1, 727: 3, 728: 1, 729: 2, 730: 1, 731: 2, 732: 1, 734: 2, 737: 1, 742: 2, 744: 1, 745: 1, 746: 1, 750: 1, 752: 1, 753: 2, 755: 1, 756: 1, 758: 1, 760: 1, 762: 2, 763: 1, 765: 1, 766: 2, 767: 2, 769: 1, 770: 1, 771: 2, 772: 1, 774: 2, 775: 2, 779: 3, 780: 1, 782: 1, 783: 1, 784: 3, 785: 1, 786: 2, 788: 2, 789: 2, 790: 2, 792: 1, 793: 2, 794: 4, 795: 1, 798: 1, 799: 1, 800: 2, 801: 1, 802: 1, 805: 1, 808: 1, 812: 1, 813: 1, 814: 2, 815: 2, 816: 3, 817: 2, 819: 3, 822: 1, 823: 2, 824: 2, 825: 3, 826: 2, 827: 6, 828: 1, 829: 4, 831: 1, 833: 2, 834: 2, 835: 1, 836: 2, 838: 2, 839: 1, 840: 2, 841: 2, 842: 3, 843: 2, 845: 1, 846: 1, 847: 4, 848: 1, 849: 3, 850: 2, 851: 1, 852: 1, 853: 1, 854: 1, 855: 1, 856: 2, 857: 1, 858: 1, 859: 1, 863: 1, 865: 1, 866: 2, 867: 1, 868: 1, 869: 2, 870: 1, 872: 1, 874: 3, 875: 1, 876: 1, 877: 1, 878: 1, 879: 1, 880: 3, 881: 1, 882: 1, 883: 3, 884: 1, 885: 1, 886: 1, 890: 1, 891: 1, 892: 2, 893: 2, 894: 1, 895: 1, 898: 1, 900: 1, 901: 2, 902: 1, 903: 2, 904: 1, 906: 1, 907: 2, 908: 2, 909: 1, 910: 3, 912: 2, 913: 1, 915: 2, 916: 1, 921: 2, 922: 1, 923: 2, 925: 1, 926: 1, 929: 3, 932: 1, 933: 1, 937: 3, 938: 1, 939: 1, 940: 1, 941: 1, 942: 1, 943: 1, 944: 1, 945: 2, 946: 6, 947: 2, 949: 2, 950: 1, 951: 1, 952: 3, 953: 2, 956: 2, 958: 1, 962: 2, 964: 2, 965: 1, 966: 3, 967: 1, 968: 3, 969: 3, 971: 1, 972: 1, 973: 2, 974: 4, 975: 1, 976: 1, 977: 3, 979: 2, 980: 1, 982: 3, 983: 2, 984: 1, 985: 3, 988: 4, 989: 2, 990: 4, 993: 2, 994: 1, 995: 1, 997: 1, 998: 3, 999: 1, 1000: 1, 1002: 2, 1008: 1, 1009: 2, 1010: 2, 1011: 1, 1015: 2, 1017: 2, 1019: 1, 1021: 1, 1025: 1, 1028: 2, 1032: 2, 1036: 1, 1038: 1, 1039: 1, 1040: 2, 1042: 1, 1043: 1, 1045: 1, 1046: 1, 1047: 2, 1048: 1, 1050: 2, 1051: 1, 1052: 1, 1054: 3, 1055: 2, 1056: 1, 1062: 2, 1063: 1, 1064: 1, 1071: 1, 1075: 1, 1076: 1, 1077: 1, 1078: 1, 1079: 1, 1080: 2, 1081: 1, 1082: 1, 1089: 2, 1090: 1, 1091: 4, 1092: 1, 1094: 2, 1095: 1, 1097: 1, 1101: 1, 1104: 1, 1105: 1, 1110: 2, 1111: 1, 1113: 3, 1117: 1, 1120: 2, 1122: 2, 1123: 1, 1125: 1, 1127: 1, 1128: 1, 1129: 1, 1131: 3, 1132: 2, 1133: 3, 1135: 1, 1138: 1, 1139: 1, 1140: 1, 1141: 1, 1143: 1, 1144: 1, 1146: 1, 1147: 1, 1150: 2, 1151: 1, 1152: 3, 1156: 1, 1159: 2, 1166: 1, 1168: 1, 1169: 1, 1172: 2, 1173: 1, 1177: 1, 1182: 2, 1185: 2, 1186: 3, 1193: 1, 1194: 1, 1195: 2, 1196: 1, 1199: 1, 1201: 1, 1202: 3, 1205: 1, 1206: 1, 1209: 1, 1211: 2, 1212: 1, 1213: 1, 1214: 1, 1215: 2, 1219: 2, 1220: 1, 1223: 1, 1224: 1, 1226: 2, 1227: 1, 1228: 1, 1229: 1, 1231: 1, 1233: 1, 1236: 1, 1237: 3, 1238: 3, 1241: 1, 1242: 1, 1243: 2, 1244: 1, 1245: 1, 1249: 1, 1255: 2, 1260: 1, 1264: 1, 1267: 1, 1271: 1, 1273: 1, 1274: 1, 1282: 2, 1285: 1, 1287: 1, 1294: 1, 1295: 1, 1302: 1, 1305: 1}\n",
            "\n",
            "Step 2: Creating label mapping...\n",
            "\n",
            "Label Mapping (original -> new):\n",
            "  22 -> 1\n",
            "  23 -> 2\n",
            "  27 -> 3\n",
            "  28 -> 4\n",
            "  29 -> 5\n",
            "  46 -> 6\n",
            "  53 -> 7\n",
            "  55 -> 8\n",
            "  56 -> 9\n",
            "  57 -> 10\n",
            "  58 -> 11\n",
            "  61 -> 12\n",
            "  69 -> 13\n",
            "  86 -> 14\n",
            "  91 -> 15\n",
            "  98 -> 16\n",
            "  99 -> 17\n",
            "  100 -> 18\n",
            "  101 -> 19\n",
            "  102 -> 20\n",
            "  107 -> 21\n",
            "  109 -> 22\n",
            "  110 -> 23\n",
            "  112 -> 24\n",
            "  113 -> 25\n",
            "  116 -> 26\n",
            "  120 -> 27\n",
            "  122 -> 28\n",
            "  124 -> 29\n",
            "  128 -> 30\n",
            "  138 -> 31\n",
            "  142 -> 32\n",
            "  148 -> 33\n",
            "  150 -> 34\n",
            "  157 -> 35\n",
            "  161 -> 36\n",
            "  163 -> 37\n",
            "  164 -> 38\n",
            "  166 -> 39\n",
            "  167 -> 40\n",
            "  172 -> 41\n",
            "  175 -> 42\n",
            "  178 -> 43\n",
            "  180 -> 44\n",
            "  183 -> 45\n",
            "  185 -> 46\n",
            "  186 -> 47\n",
            "  187 -> 48\n",
            "  192 -> 49\n",
            "  198 -> 50\n",
            "  201 -> 51\n",
            "  203 -> 52\n",
            "  204 -> 53\n",
            "  206 -> 54\n",
            "  209 -> 55\n",
            "  212 -> 56\n",
            "  213 -> 57\n",
            "  218 -> 58\n",
            "  224 -> 59\n",
            "  229 -> 60\n",
            "  230 -> 61\n",
            "  233 -> 62\n",
            "  235 -> 63\n",
            "  236 -> 64\n",
            "  237 -> 65\n",
            "  239 -> 66\n",
            "  240 -> 67\n",
            "  241 -> 68\n",
            "  242 -> 69\n",
            "  243 -> 70\n",
            "  244 -> 71\n",
            "  247 -> 72\n",
            "  248 -> 73\n",
            "  249 -> 74\n",
            "  252 -> 75\n",
            "  253 -> 76\n",
            "  256 -> 77\n",
            "  257 -> 78\n",
            "  259 -> 79\n",
            "  260 -> 80\n",
            "  262 -> 81\n",
            "  264 -> 82\n",
            "  266 -> 83\n",
            "  267 -> 84\n",
            "  271 -> 85\n",
            "  273 -> 86\n",
            "  275 -> 87\n",
            "  278 -> 88\n",
            "  283 -> 89\n",
            "  284 -> 90\n",
            "  285 -> 91\n",
            "  288 -> 92\n",
            "  290 -> 93\n",
            "  291 -> 94\n",
            "  293 -> 95\n",
            "  294 -> 96\n",
            "  296 -> 97\n",
            "  297 -> 98\n",
            "  298 -> 99\n",
            "  302 -> 100\n",
            "  306 -> 101\n",
            "  307 -> 102\n",
            "  310 -> 103\n",
            "  311 -> 104\n",
            "  312 -> 105\n",
            "  314 -> 106\n",
            "  315 -> 107\n",
            "  316 -> 108\n",
            "  318 -> 109\n",
            "  323 -> 110\n",
            "  325 -> 111\n",
            "  327 -> 112\n",
            "  330 -> 113\n",
            "  335 -> 114\n",
            "  338 -> 115\n",
            "  339 -> 116\n",
            "  341 -> 117\n",
            "  344 -> 118\n",
            "  346 -> 119\n",
            "  350 -> 120\n",
            "  351 -> 121\n",
            "  353 -> 122\n",
            "  354 -> 123\n",
            "  355 -> 124\n",
            "  358 -> 125\n",
            "  359 -> 126\n",
            "  361 -> 127\n",
            "  365 -> 128\n",
            "  366 -> 129\n",
            "  367 -> 130\n",
            "  369 -> 131\n",
            "  377 -> 132\n",
            "  378 -> 133\n",
            "  379 -> 134\n",
            "  380 -> 135\n",
            "  381 -> 136\n",
            "  382 -> 137\n",
            "  383 -> 138\n",
            "  386 -> 139\n",
            "  389 -> 140\n",
            "  391 -> 141\n",
            "  392 -> 142\n",
            "  394 -> 143\n",
            "  396 -> 144\n",
            "  398 -> 145\n",
            "  401 -> 146\n",
            "  403 -> 147\n",
            "  407 -> 148\n",
            "  409 -> 149\n",
            "  410 -> 150\n",
            "  411 -> 151\n",
            "  412 -> 152\n",
            "  413 -> 153\n",
            "  420 -> 154\n",
            "  421 -> 155\n",
            "  423 -> 156\n",
            "  425 -> 157\n",
            "  430 -> 158\n",
            "  432 -> 159\n",
            "  438 -> 160\n",
            "  439 -> 161\n",
            "  440 -> 162\n",
            "  442 -> 163\n",
            "  445 -> 164\n",
            "  446 -> 165\n",
            "  451 -> 166\n",
            "  453 -> 167\n",
            "  454 -> 168\n",
            "  455 -> 169\n",
            "  456 -> 170\n",
            "  457 -> 171\n",
            "  458 -> 172\n",
            "  460 -> 173\n",
            "  461 -> 174\n",
            "  463 -> 175\n",
            "  467 -> 176\n",
            "  470 -> 177\n",
            "  471 -> 178\n",
            "  474 -> 179\n",
            "  475 -> 180\n",
            "  477 -> 181\n",
            "  483 -> 182\n",
            "  484 -> 183\n",
            "  486 -> 184\n",
            "  490 -> 185\n",
            "  491 -> 186\n",
            "  492 -> 187\n",
            "  494 -> 188\n",
            "  496 -> 189\n",
            "  500 -> 190\n",
            "  502 -> 191\n",
            "  504 -> 192\n",
            "  505 -> 193\n",
            "  507 -> 194\n",
            "  509 -> 195\n",
            "  510 -> 196\n",
            "  511 -> 197\n",
            "  514 -> 198\n",
            "  517 -> 199\n",
            "  518 -> 200\n",
            "  519 -> 201\n",
            "  520 -> 202\n",
            "  521 -> 203\n",
            "  527 -> 204\n",
            "  528 -> 205\n",
            "  532 -> 206\n",
            "  533 -> 207\n",
            "  534 -> 208\n",
            "  537 -> 209\n",
            "  538 -> 210\n",
            "  544 -> 211\n",
            "  549 -> 212\n",
            "  551 -> 213\n",
            "  553 -> 214\n",
            "  555 -> 215\n",
            "  558 -> 216\n",
            "  568 -> 217\n",
            "  569 -> 218\n",
            "  575 -> 219\n",
            "  579 -> 220\n",
            "  581 -> 221\n",
            "  584 -> 222\n",
            "  589 -> 223\n",
            "  593 -> 224\n",
            "  594 -> 225\n",
            "  597 -> 226\n",
            "  599 -> 227\n",
            "  601 -> 228\n",
            "  602 -> 229\n",
            "  603 -> 230\n",
            "  605 -> 231\n",
            "  610 -> 232\n",
            "  616 -> 233\n",
            "  617 -> 234\n",
            "  625 -> 235\n",
            "  627 -> 236\n",
            "  631 -> 237\n",
            "  634 -> 238\n",
            "  638 -> 239\n",
            "  644 -> 240\n",
            "  646 -> 241\n",
            "  648 -> 242\n",
            "  650 -> 243\n",
            "  655 -> 244\n",
            "  656 -> 245\n",
            "  657 -> 246\n",
            "  658 -> 247\n",
            "  662 -> 248\n",
            "  667 -> 249\n",
            "  668 -> 250\n",
            "  670 -> 251\n",
            "  671 -> 252\n",
            "  675 -> 253\n",
            "  677 -> 254\n",
            "  678 -> 255\n",
            "  680 -> 256\n",
            "  681 -> 257\n",
            "  683 -> 258\n",
            "  686 -> 259\n",
            "  689 -> 260\n",
            "  692 -> 261\n",
            "  693 -> 262\n",
            "  695 -> 263\n",
            "  696 -> 264\n",
            "  698 -> 265\n",
            "  699 -> 266\n",
            "  700 -> 267\n",
            "  702 -> 268\n",
            "  703 -> 269\n",
            "  705 -> 270\n",
            "  707 -> 271\n",
            "  708 -> 272\n",
            "  710 -> 273\n",
            "  711 -> 274\n",
            "  712 -> 275\n",
            "  713 -> 276\n",
            "  717 -> 277\n",
            "  718 -> 278\n",
            "  720 -> 279\n",
            "  721 -> 280\n",
            "  723 -> 281\n",
            "  724 -> 282\n",
            "  726 -> 283\n",
            "  727 -> 284\n",
            "  728 -> 285\n",
            "  729 -> 286\n",
            "  730 -> 287\n",
            "  731 -> 288\n",
            "  732 -> 289\n",
            "  734 -> 290\n",
            "  737 -> 291\n",
            "  742 -> 292\n",
            "  744 -> 293\n",
            "  745 -> 294\n",
            "  746 -> 295\n",
            "  750 -> 296\n",
            "  752 -> 297\n",
            "  753 -> 298\n",
            "  755 -> 299\n",
            "  756 -> 300\n",
            "  758 -> 301\n",
            "  760 -> 302\n",
            "  762 -> 303\n",
            "  763 -> 304\n",
            "  765 -> 305\n",
            "  766 -> 306\n",
            "  767 -> 307\n",
            "  769 -> 308\n",
            "  770 -> 309\n",
            "  771 -> 310\n",
            "  772 -> 311\n",
            "  774 -> 312\n",
            "  775 -> 313\n",
            "  779 -> 314\n",
            "  780 -> 315\n",
            "  782 -> 316\n",
            "  783 -> 317\n",
            "  784 -> 318\n",
            "  785 -> 319\n",
            "  786 -> 320\n",
            "  788 -> 321\n",
            "  789 -> 322\n",
            "  790 -> 323\n",
            "  792 -> 324\n",
            "  793 -> 325\n",
            "  794 -> 326\n",
            "  795 -> 327\n",
            "  798 -> 328\n",
            "  799 -> 329\n",
            "  800 -> 330\n",
            "  801 -> 331\n",
            "  802 -> 332\n",
            "  805 -> 333\n",
            "  808 -> 334\n",
            "  812 -> 335\n",
            "  813 -> 336\n",
            "  814 -> 337\n",
            "  815 -> 338\n",
            "  816 -> 339\n",
            "  817 -> 340\n",
            "  819 -> 341\n",
            "  822 -> 342\n",
            "  823 -> 343\n",
            "  824 -> 344\n",
            "  825 -> 345\n",
            "  826 -> 346\n",
            "  827 -> 347\n",
            "  828 -> 348\n",
            "  829 -> 349\n",
            "  831 -> 350\n",
            "  833 -> 351\n",
            "  834 -> 352\n",
            "  835 -> 353\n",
            "  836 -> 354\n",
            "  838 -> 355\n",
            "  839 -> 356\n",
            "  840 -> 357\n",
            "  841 -> 358\n",
            "  842 -> 359\n",
            "  843 -> 360\n",
            "  845 -> 361\n",
            "  846 -> 362\n",
            "  847 -> 363\n",
            "  848 -> 364\n",
            "  849 -> 365\n",
            "  850 -> 366\n",
            "  851 -> 367\n",
            "  852 -> 368\n",
            "  853 -> 369\n",
            "  854 -> 370\n",
            "  855 -> 371\n",
            "  856 -> 372\n",
            "  857 -> 373\n",
            "  858 -> 374\n",
            "  859 -> 375\n",
            "  863 -> 376\n",
            "  865 -> 377\n",
            "  866 -> 378\n",
            "  867 -> 379\n",
            "  868 -> 380\n",
            "  869 -> 381\n",
            "  870 -> 382\n",
            "  872 -> 383\n",
            "  874 -> 384\n",
            "  875 -> 385\n",
            "  876 -> 386\n",
            "  877 -> 387\n",
            "  878 -> 388\n",
            "  879 -> 389\n",
            "  880 -> 390\n",
            "  881 -> 391\n",
            "  882 -> 392\n",
            "  883 -> 393\n",
            "  884 -> 394\n",
            "  885 -> 395\n",
            "  886 -> 396\n",
            "  890 -> 397\n",
            "  891 -> 398\n",
            "  892 -> 399\n",
            "  893 -> 400\n",
            "  894 -> 401\n",
            "  895 -> 402\n",
            "  898 -> 403\n",
            "  900 -> 404\n",
            "  901 -> 405\n",
            "  902 -> 406\n",
            "  903 -> 407\n",
            "  904 -> 408\n",
            "  906 -> 409\n",
            "  907 -> 410\n",
            "  908 -> 411\n",
            "  909 -> 412\n",
            "  910 -> 413\n",
            "  912 -> 414\n",
            "  913 -> 415\n",
            "  915 -> 416\n",
            "  916 -> 417\n",
            "  921 -> 418\n",
            "  922 -> 419\n",
            "  923 -> 420\n",
            "  925 -> 421\n",
            "  926 -> 422\n",
            "  929 -> 423\n",
            "  932 -> 424\n",
            "  933 -> 425\n",
            "  937 -> 426\n",
            "  938 -> 427\n",
            "  939 -> 428\n",
            "  940 -> 429\n",
            "  941 -> 430\n",
            "  942 -> 431\n",
            "  943 -> 432\n",
            "  944 -> 433\n",
            "  945 -> 434\n",
            "  946 -> 435\n",
            "  947 -> 436\n",
            "  949 -> 437\n",
            "  950 -> 438\n",
            "  951 -> 439\n",
            "  952 -> 440\n",
            "  953 -> 441\n",
            "  956 -> 442\n",
            "  958 -> 443\n",
            "  962 -> 444\n",
            "  964 -> 445\n",
            "  965 -> 446\n",
            "  966 -> 447\n",
            "  967 -> 448\n",
            "  968 -> 449\n",
            "  969 -> 450\n",
            "  971 -> 451\n",
            "  972 -> 452\n",
            "  973 -> 453\n",
            "  974 -> 454\n",
            "  975 -> 455\n",
            "  976 -> 456\n",
            "  977 -> 457\n",
            "  979 -> 458\n",
            "  980 -> 459\n",
            "  982 -> 460\n",
            "  983 -> 461\n",
            "  984 -> 462\n",
            "  985 -> 463\n",
            "  988 -> 464\n",
            "  989 -> 465\n",
            "  990 -> 466\n",
            "  993 -> 467\n",
            "  994 -> 468\n",
            "  995 -> 469\n",
            "  997 -> 470\n",
            "  998 -> 471\n",
            "  999 -> 472\n",
            "  1000 -> 473\n",
            "  1002 -> 474\n",
            "  1008 -> 475\n",
            "  1009 -> 476\n",
            "  1010 -> 477\n",
            "  1011 -> 478\n",
            "  1015 -> 479\n",
            "  1017 -> 480\n",
            "  1019 -> 481\n",
            "  1021 -> 482\n",
            "  1025 -> 483\n",
            "  1028 -> 484\n",
            "  1032 -> 485\n",
            "  1036 -> 486\n",
            "  1038 -> 487\n",
            "  1039 -> 488\n",
            "  1040 -> 489\n",
            "  1042 -> 490\n",
            "  1043 -> 491\n",
            "  1045 -> 492\n",
            "  1046 -> 493\n",
            "  1047 -> 494\n",
            "  1048 -> 495\n",
            "  1050 -> 496\n",
            "  1051 -> 497\n",
            "  1052 -> 498\n",
            "  1054 -> 499\n",
            "  1055 -> 500\n",
            "  1056 -> 501\n",
            "  1062 -> 502\n",
            "  1063 -> 503\n",
            "  1064 -> 504\n",
            "  1071 -> 505\n",
            "  1075 -> 506\n",
            "  1076 -> 507\n",
            "  1077 -> 508\n",
            "  1078 -> 509\n",
            "  1079 -> 510\n",
            "  1080 -> 511\n",
            "  1081 -> 512\n",
            "  1082 -> 513\n",
            "  1089 -> 514\n",
            "  1090 -> 515\n",
            "  1091 -> 516\n",
            "  1092 -> 517\n",
            "  1094 -> 518\n",
            "  1095 -> 519\n",
            "  1097 -> 520\n",
            "  1101 -> 521\n",
            "  1104 -> 522\n",
            "  1105 -> 523\n",
            "  1110 -> 524\n",
            "  1111 -> 525\n",
            "  1113 -> 526\n",
            "  1117 -> 527\n",
            "  1120 -> 528\n",
            "  1122 -> 529\n",
            "  1123 -> 530\n",
            "  1125 -> 531\n",
            "  1127 -> 532\n",
            "  1128 -> 533\n",
            "  1129 -> 534\n",
            "  1131 -> 535\n",
            "  1132 -> 536\n",
            "  1133 -> 537\n",
            "  1135 -> 538\n",
            "  1138 -> 539\n",
            "  1139 -> 540\n",
            "  1140 -> 541\n",
            "  1141 -> 542\n",
            "  1143 -> 543\n",
            "  1144 -> 544\n",
            "  1146 -> 545\n",
            "  1147 -> 546\n",
            "  1150 -> 547\n",
            "  1151 -> 548\n",
            "  1152 -> 549\n",
            "  1156 -> 550\n",
            "  1159 -> 551\n",
            "  1166 -> 552\n",
            "  1168 -> 553\n",
            "  1169 -> 554\n",
            "  1172 -> 555\n",
            "  1173 -> 556\n",
            "  1177 -> 557\n",
            "  1182 -> 558\n",
            "  1185 -> 559\n",
            "  1186 -> 560\n",
            "  1193 -> 561\n",
            "  1194 -> 562\n",
            "  1195 -> 563\n",
            "  1196 -> 564\n",
            "  1199 -> 565\n",
            "  1201 -> 566\n",
            "  1202 -> 567\n",
            "  1205 -> 568\n",
            "  1206 -> 569\n",
            "  1209 -> 570\n",
            "  1211 -> 571\n",
            "  1212 -> 572\n",
            "  1213 -> 573\n",
            "  1214 -> 574\n",
            "  1215 -> 575\n",
            "  1219 -> 576\n",
            "  1220 -> 577\n",
            "  1223 -> 578\n",
            "  1224 -> 579\n",
            "  1226 -> 580\n",
            "  1227 -> 581\n",
            "  1228 -> 582\n",
            "  1229 -> 583\n",
            "  1231 -> 584\n",
            "  1233 -> 585\n",
            "  1236 -> 586\n",
            "  1237 -> 587\n",
            "  1238 -> 588\n",
            "  1241 -> 589\n",
            "  1242 -> 590\n",
            "  1243 -> 591\n",
            "  1244 -> 592\n",
            "  1245 -> 593\n",
            "  1249 -> 594\n",
            "  1255 -> 595\n",
            "  1260 -> 596\n",
            "  1264 -> 597\n",
            "  1267 -> 598\n",
            "  1271 -> 599\n",
            "  1273 -> 600\n",
            "  1274 -> 601\n",
            "  1282 -> 602\n",
            "  1285 -> 603\n",
            "  1287 -> 604\n",
            "  1294 -> 605\n",
            "  1295 -> 606\n",
            "  1302 -> 607\n",
            "  1305 -> 608\n",
            "\n",
            "Step 3: Number of classes (including background): 609\n",
            "\n",
            "Step 4: Creating model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 5: Creating datasets...\n",
            "\n",
            "Step 7: Setting up training...\n",
            "Label mapping saved to label_mapping.pkl\n",
            "\n",
            "Setup complete!\n",
            "- Original labels: [22, 23, 27, 28, 29, 46, 53, 55, 56, 57, 58, 61, 69, 86, 91, 98, 99, 100, 101, 102, 107, 109, 110, 112, 113, 116, 120, 122, 124, 128, 138, 142, 148, 150, 157, 161, 163, 164, 166, 167, 172, 175, 178, 180, 183, 185, 186, 187, 192, 198, 201, 203, 204, 206, 209, 212, 213, 218, 224, 229, 230, 233, 235, 236, 237, 239, 240, 241, 242, 243, 244, 247, 248, 249, 252, 253, 256, 257, 259, 260, 262, 264, 266, 267, 271, 273, 275, 278, 283, 284, 285, 288, 290, 291, 293, 294, 296, 297, 298, 302, 306, 307, 310, 311, 312, 314, 315, 316, 318, 323, 325, 327, 330, 335, 338, 339, 341, 344, 346, 350, 351, 353, 354, 355, 358, 359, 361, 365, 366, 367, 369, 377, 378, 379, 380, 381, 382, 383, 386, 389, 391, 392, 394, 396, 398, 401, 403, 407, 409, 410, 411, 412, 413, 420, 421, 423, 425, 430, 432, 438, 439, 440, 442, 445, 446, 451, 453, 454, 455, 456, 457, 458, 460, 461, 463, 467, 470, 471, 474, 475, 477, 483, 484, 486, 490, 491, 492, 494, 496, 500, 502, 504, 505, 507, 509, 510, 511, 514, 517, 518, 519, 520, 521, 527, 528, 532, 533, 534, 537, 538, 544, 549, 551, 553, 555, 558, 568, 569, 575, 579, 581, 584, 589, 593, 594, 597, 599, 601, 602, 603, 605, 610, 616, 617, 625, 627, 631, 634, 638, 644, 646, 648, 650, 655, 656, 657, 658, 662, 667, 668, 670, 671, 675, 677, 678, 680, 681, 683, 686, 689, 692, 693, 695, 696, 698, 699, 700, 702, 703, 705, 707, 708, 710, 711, 712, 713, 717, 718, 720, 721, 723, 724, 726, 727, 728, 729, 730, 731, 732, 734, 737, 742, 744, 745, 746, 750, 752, 753, 755, 756, 758, 760, 762, 763, 765, 766, 767, 769, 770, 771, 772, 774, 775, 779, 780, 782, 783, 784, 785, 786, 788, 789, 790, 792, 793, 794, 795, 798, 799, 800, 801, 802, 805, 808, 812, 813, 814, 815, 816, 817, 819, 822, 823, 824, 825, 826, 827, 828, 829, 831, 833, 834, 835, 836, 838, 839, 840, 841, 842, 843, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 863, 865, 866, 867, 868, 869, 870, 872, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 890, 891, 892, 893, 894, 895, 898, 900, 901, 902, 903, 904, 906, 907, 908, 909, 910, 912, 913, 915, 916, 921, 922, 923, 925, 926, 929, 932, 933, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 949, 950, 951, 952, 953, 956, 958, 962, 964, 965, 966, 967, 968, 969, 971, 972, 973, 974, 975, 976, 977, 979, 980, 982, 983, 984, 985, 988, 989, 990, 993, 994, 995, 997, 998, 999, 1000, 1002, 1008, 1009, 1010, 1011, 1015, 1017, 1019, 1021, 1025, 1028, 1032, 1036, 1038, 1039, 1040, 1042, 1043, 1045, 1046, 1047, 1048, 1050, 1051, 1052, 1054, 1055, 1056, 1062, 1063, 1064, 1071, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1089, 1090, 1091, 1092, 1094, 1095, 1097, 1101, 1104, 1105, 1110, 1111, 1113, 1117, 1120, 1122, 1123, 1125, 1127, 1128, 1129, 1131, 1132, 1133, 1135, 1138, 1139, 1140, 1141, 1143, 1144, 1146, 1147, 1150, 1151, 1152, 1156, 1159, 1166, 1168, 1169, 1172, 1173, 1177, 1182, 1185, 1186, 1193, 1194, 1195, 1196, 1199, 1201, 1202, 1205, 1206, 1209, 1211, 1212, 1213, 1214, 1215, 1219, 1220, 1223, 1224, 1226, 1227, 1228, 1229, 1231, 1233, 1236, 1237, 1238, 1241, 1242, 1243, 1244, 1245, 1249, 1255, 1260, 1264, 1267, 1271, 1273, 1274, 1282, 1285, 1287, 1294, 1295, 1302, 1305]\n",
            "- Mapped labels: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608]\n",
            "- Total classes (including background): 609\n",
            "- Training samples: 506\n",
            "- Test samples: 506\n",
            "\n",
            "Step 9: Testing data loader...\n",
            " Data loader working correctly!\n",
            "  Batch size: 4\n",
            "  Sample labels in batch: [457, 84]\n",
            "\n",
            "You can now start training with:\n",
            "- model: FasterRCNN\n",
            "- data_loader: 127 batches\n",
            "- data_loader_test: 506 batches\n",
            "- device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from engine import train_one_epoch, evaluate\n",
        "import my_utils\n",
        "from IPython.display import clear_output\n",
        "import pickle\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set model to training mode\n",
        "model.train()\n",
        "\n",
        "# Training configuration\n",
        "num_epochs = 100\n",
        "print_freq = 50\n",
        "\n",
        "# Initialize tracking lists\n",
        "losses = []\n",
        "loss_box_reg = []\n",
        "loss_rpn_box_reg = []\n",
        "loss_classifier = []\n",
        "loss_objectness = []\n",
        "\n",
        "# COCO evaluation metrics\n",
        "stat0 = []  # mAP @ IoU=0.50:0.95 | area=all | maxDets=100\n",
        "stat1 = []  # mAP @ IoU=0.50 | area=all | maxDets=100\n",
        "stat2 = []  # mAP @ IoU=0.75 | area=all | maxDets=100\n",
        "stat3 = []  # mAP @ IoU=0.50:0.95 | area=small | maxDets=100\n",
        "stat4 = []  # mAP @ IoU=0.50:0.95 | area=medium | maxDets=100\n",
        "stat5 = []  # mAP @ IoU=0.50:0.95 | area=large | maxDets=100\n",
        "stat6 = []  # mAR @ IoU=0.50:0.95 | area=all | maxDets=1\n",
        "stat7 = []  # mAR @ IoU=0.50:0.95 | area=all | maxDets=10\n",
        "stat8 = []  # mAR @ IoU=0.50:0.95 | area=all | maxDets=100\n",
        "stat9 = []  # mAR @ IoU=0.50:0.95 | area=small | maxDets=100\n",
        "stat10 = [] # mAR @ IoU=0.50:0.95 | area=medium | maxDets=100\n",
        "stat11 = [] # mAR @ IoU=0.50:0.95 | area=large | maxDets=100\n",
        "\n",
        "print(f\"Starting training for {num_epochs} epochs...\")\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"Model classes: {num_classes}\")\n",
        "print(f\"Training batches: {len(data_loader)}\")\n",
        "print(f\"Test batches: {len(data_loader_test)}\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    try:\n",
        "        metrics = train_one_epoch(model, optimizer, data_loader, device, epoch)\n",
        "\n",
        "        # Extract training losses\n",
        "        losses.append(float(str(metrics.meters['loss']).split(\" \")[0]))\n",
        "        loss_box_reg.append(float(str(metrics.meters['loss_box_reg']).split(\" \")[0]))\n",
        "        loss_rpn_box_reg.append(float(str(metrics.meters['loss_rpn_box_reg']).split(\" \")[0]))\n",
        "        loss_classifier.append(float(str(metrics.meters['loss_classifier']).split(\" \")[0]))\n",
        "        loss_objectness.append(float(str(metrics.meters['loss_objectness']).split(\" \")[0]))\n",
        "\n",
        "        print(f\"Training - Loss: {losses[-1]:.4f}, Box Reg: {loss_box_reg[-1]:.4f}, \"\n",
        "              f\"Classifier: {loss_classifier[-1]:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during training: {e}\")\n",
        "        break\n",
        "\n",
        "    # Update learning rate\n",
        "    lr_scheduler.step()\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"Learning Rate: {current_lr:.6f}\")\n",
        "\n",
        "    # Evaluation phase\n",
        "    try:\n",
        "        model.eval()\n",
        "        coco_evaluator, metric_logger = evaluate(model, data_loader_test, device=device)\n",
        "\n",
        "        # Extract COCO evaluation stats\n",
        "        stats = coco_evaluator.coco_eval['bbox'].stats\n",
        "\n",
        "        stat0.append(stats[0])   # mAP @ IoU=0.50:0.95\n",
        "        stat1.append(stats[1])   # mAP @ IoU=0.50\n",
        "        stat2.append(stats[2])   # mAP @ IoU=0.75\n",
        "        stat3.append(stats[3])   # mAP small\n",
        "        stat4.append(stats[4])   # mAP medium\n",
        "        stat5.append(stats[5])   # mAP large\n",
        "        stat6.append(stats[6])   # mAR @ maxDets=1\n",
        "        stat7.append(stats[7])   # mAR @ maxDets=10\n",
        "        stat8.append(stats[8])   # mAR @ maxDets=100\n",
        "        stat9.append(stats[9])   # mAR small\n",
        "        stat10.append(stats[10]) # mAR medium\n",
        "        stat11.append(stats[11]) # mAR large\n",
        "\n",
        "        print(f\"Evaluation - mAP@0.5:0.95: {stat0[-1]:.4f}, mAP@0.5: {stat1[-1]:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during evaluation: {e}\")\n",
        "        # Fill with zeros if evaluation fails\n",
        "        for stat_list in [stat0, stat1, stat2, stat3, stat4, stat5, stat6, stat7, stat8, stat9, stat10, stat11]:\n",
        "            stat_list.append(0.0)\n",
        "\n",
        "    # Save checkpoint every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': lr_scheduler.state_dict(),\n",
        "            'losses': losses,\n",
        "            'mAP_50_95': stat0,\n",
        "            'mAP_50': stat1,\n",
        "            'label_mapping': label_mapping,\n",
        "            'num_classes': num_classes\n",
        "        }\n",
        "        torch.save(checkpoint, f'checkpoint_epoch_{epoch + 1}.pth')\n",
        "        print(f\"Checkpoint saved: checkpoint_epoch_{epoch + 1}.pth\")\n",
        "\n",
        "    # Plot progress every 20 epochs\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # Plot losses\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.plot(losses, label='Total Loss')\n",
        "        plt.plot(loss_classifier, label='Classifier Loss')\n",
        "        plt.plot(loss_box_reg, label='Box Regression Loss')\n",
        "        plt.title('Training Losses')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Plot mAP\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.plot(stat0, label='mAP@0.5:0.95')\n",
        "        plt.plot(stat1, label='mAP@0.5')\n",
        "        plt.title('Mean Average Precision')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('mAP')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Plot learning rate\n",
        "        plt.subplot(1, 3, 3)\n",
        "        lrs = [losses[i] for i in range(len(losses))]  # You might want to track LR separately\n",
        "        plt.plot(range(len(losses)), [current_lr] * len(losses))\n",
        "        plt.title('Learning Rate')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('LR')\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'training_progress_epoch_{epoch + 1}.png', dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "    print('-' * 50)\n",
        "\n",
        "    # Early stopping condition (optional)\n",
        "    if len(stat0) > 50 and stat0[-1] < 0.001:  # If mAP is very low for too long\n",
        "        print(\"Early stopping: mAP not improving\")\n",
        "        break\n",
        "\n",
        "print(\"\\nTraining completed!\")\n",
        "\n",
        "# Save final results\n",
        "final_results = {\n",
        "    'losses': losses,\n",
        "    'loss_box_reg': loss_box_reg,\n",
        "    'loss_rpn_box_reg': loss_rpn_box_reg,\n",
        "    'loss_classifier': loss_classifier,\n",
        "    'loss_objectness': loss_objectness,\n",
        "    'mAP_50_95': stat0,\n",
        "    'mAP_50': stat1,\n",
        "    'mAP_75': stat2,\n",
        "    'mAP_small': stat3,\n",
        "    'mAP_medium': stat4,\n",
        "    'mAP_large': stat5,\n",
        "    'mAR_1': stat6,\n",
        "    'mAR_10': stat7,\n",
        "    'mAR_100': stat8,\n",
        "    'mAR_small': stat9,\n",
        "    'mAR_medium': stat10,\n",
        "    'mAR_large': stat11,\n",
        "    'label_mapping': label_mapping,\n",
        "    'reverse_mapping': reverse_mapping,\n",
        "    'num_classes': num_classes,\n",
        "    'total_epochs': len(losses)\n",
        "}\n",
        "\n",
        "# Save results\n",
        "with open('final_training_results.pkl', 'wb') as f:\n",
        "    pickle.dump(final_results, f)\n",
        "\n",
        "# Save final model\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'label_mapping': label_mapping,\n",
        "    'reverse_mapping': reverse_mapping,\n",
        "    'num_classes': num_classes\n",
        "}, 'final_model.pth')\n",
        "\n",
        "print(\"Results saved to:\")\n",
        "print(\"- final_training_results.pkl\")\n",
        "print(\"- final_model.pth\")\n",
        "\n",
        "# Print summary\n",
        "if len(losses) > 0:\n",
        "    print(f\"\\nTraining Summary:\")\n",
        "    print(f\"Total epochs completed: {len(losses)}\")\n",
        "    print(f\"Final loss: {losses[-1]:.4f}\")\n",
        "    if len(stat0) > 0:\n",
        "        print(f\"Final mAP@0.5:0.95: {stat0[-1]:.4f}\")\n",
        "        print(f\"Final mAP@0.5: {stat1[-1]:.4f}\")\n",
        "        print(f\"Best mAP@0.5:0.95: {max(stat0):.4f} (epoch {stat0.index(max(stat0)) + 1})\")\n",
        "        print(f\"Best mAP@0.5: {max(stat1):.4f} (epoch {stat1.index(max(stat1)) + 1})\")\n",
        "\n",
        "print(\"\\nTraining finished successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "Wxt4o84Giry2",
        "outputId": "2c5f66ca-8463-4c24-b8f6-f94afaadb38b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'engine'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2115855444.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmy_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'engine'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -r \"def train_one_epoch\" /content/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMiBT6NujULq",
        "outputId": "3cf6eddc-25ed-4b89-aef9-e411d49fbf34"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grep: /content/drive/MyDrive/Progression of Models of Motorcars (4).gslides: Operation not supported\n",
            "grep: /content/drive/MyDrive/Progression of Models of Motorcars (3).gslides: Operation not supported\n",
            "grep: /content/drive/MyDrive/Progression of Models of Motorcars (2).gslides: Operation not supported\n",
            "grep: /content/drive/MyDrive/Progression of Models of Motorcars (1).gslides: Operation not supported\n",
            "grep: /content/drive/MyDrive/Progression of Models of Motorcars.gslides: Operation not supported\n",
            "grep: /content/drive/MyDrive/art of weaving.gslides: Operation not supported\n",
            "grep: /content/drive/MyDrive/Copy of TMP MASTER LOG BOOK VER 3.0 TEMPLATE.gsheet: Operation not supported\n",
            "grep: /content/drive/MyDrive/BADRI LIVE EV DASHBOARD .gsheet: Operation not supported\n",
            "/content/drive/MyDrive/Colab Notebooks/Untitled10.ipynb:{\"nbformat\":4,\"nbformat_minor\":0,\"metadata\":{\"colab\":{\"provenance\":[],\"gpuType\":\"T4\",\"mount_file_id\":\"19jvWsqTF9VPeYoDDjVIUk0YGcufDwvk4\",\"authorship_tag\":\"ABX9TyPdRG04ZonlVBeTeV2w1dPf\"},\"kernelspec\":{\"name\":\"python3\",\"display_name\":\"Python 3\"},\"language_info\":{\"name\":\"python\"},\"accelerator\":\"GPU\"},\"cells\":[{\"cell_type\":\"code\",\"execution_count\":1,\"metadata\":{\"id\":\"LkXp9tigFTuo\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217731236,\"user_tz\":-330,\"elapsed\":3029,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}}},\"outputs\":[],\"source\":[\"import os\\n\",\"import numpy as np\\n\",\"import pandas as pd\\n\",\"from glob import glob\\n\",\"import cv2\\n\",\"import torch\\n\",\"from torch.utils import data\\n\",\"from PIL import Image\\n\",\"import torchvision\\n\",\"from torchvision import transforms\\n\",\"import matplotlib.pyplot as plt\"]},{\"cell_type\":\"code\",\"source\":[\"from google.colab import drive\\n\",\"drive.mount('/content/drive')\\n\",\"import os\\n\",\"\\n\",\"folder_path = '/content/drive/MyDrive/object_detect_gtsdb'\\n\",\"files = os.listdir(folder_path)\\n\",\"print(files)\\n\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"AJ1kSlImI9P9\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217735354,\"user_tz\":-330,\"elapsed\":1909,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"51ac9e03-7ac2-45f5-f6ef-32b76b5b4a3e\"},\"execution_count\":2,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\\\"/content/drive\\\", force_remount=True).\\n\",\"['imagesf', 'gt.txt', 'label_mapping.pkl', '__pycache__', 'util', 'my_datasets', 'engine.py', 'coco_utils.py', 'utils.py']\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"txt = np.genfromtxt('/content/drive/MyDrive/object_detect_gtsdb/gt.txt',delimiter =';', dtype= None,encoding=None)\\n\",\"\\n\",\"#Creating a dictionary with image names as key and annotations as value\\n\",\"dic ={}\\n\",\"for i in range (0,len(txt)):\\n\",\"    #Image name is first element of annotation file\\n\",\"    img_name = txt[i][0]\\n\",\"    # 4 Coordinates\\n\",\"    target = [txt[i][1],txt[i][2],txt[i][3],txt[i][4],txt[i][5]]\\n\",\"    #Last element is the class number\\n\",\"    clas = txt[i][-1]\\n\",\"    #If multiple objects, store coordinates and classes as list of lists\\n\",\"    if(img_name in dic):\\n\",\"        dic[img_name].append(target)\\n\",\"    else:\\n\",\"        dic[img_name] = [target]\\n\",\"print(dic['00001.ppm'])\\n\",\"print(\\\"Number of Images: \\\" + str(len(dic)))\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"ijJAAUssKtNe\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217738424,\"user_tz\":-330,\"elapsed\":27,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"44b1cb15-c536-46b6-f131-6c28db5c6804\"},\"execution_count\":3,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"[[np.int64(983), np.int64(388), np.int64(1024), np.int64(432), np.int64(40)], [np.int64(386), np.int64(494), np.int64(442), np.int64(552), np.int64(38)], [np.int64(973), np.int64(335), np.int64(1031), np.int64(390), np.int64(13)]]\\n\",\"Number of Images: 506\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"dic['00001.ppm']\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"lrpb3ui1M9NX\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217741057,\"user_tz\":-330,\"elapsed\":16,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"2b348496-17b5-4da7-956c-8d482c457d04\"},\"execution_count\":4,\"outputs\":[{\"output_type\":\"execute_result\",\"data\":{\"text/plain\":[\"[[np.int64(983), np.int64(388), np.int64(1024), np.int64(432), np.int64(40)],\\n\",\" [np.int64(386), np.int64(494), np.int64(442), np.int64(552), np.int64(38)],\\n\",\" [np.int64(973), np.int64(335), np.int64(1031), np.int64(390), np.int64(13)]]\"]},\"metadata\":{},\"execution_count\":4}]},{\"cell_type\":\"code\",\"source\":[\"cls_lst = {}\\n\",\"\\n\",\"for i in dic:\\n\",\"    for j in dic[i][:]:\\n\",\"        #print(len(dic[i]))\\n\",\"        for k in range(len(dic[i])):\\n\",\"            clss = dic[i][:][k][-1]\\n\",\"            if clss in cls_lst:\\n\",\"                cls_lst[clss] += 1\\n\",\"            else:\\n\",\"                cls_lst[clss] = 1\\n\",\"\\n\",\"print(cls_lst)\\n\",\"\\n\",\"xx = []\\n\",\"yy = []\\n\",\"for i in cls_lst:\\n\",\"    xx.append(str(i))\\n\",\"    yy.append(cls_lst[i])\\n\",\"\\n\",\"x_pos = [i for i, _ in enumerate(xx)]\\n\",\"\\n\",\"plt.bar(x_pos, yy, color='green')\\n\",\"plt.xlabel(\\\"Class Number\\\")\\n\",\"plt.ylabel(\\\"Number of Examples\\\")\\n\",\"plt.title(\\\"GTSDB\\\")\\n\",\"#plt.figure(figsize=(30,30))\\n\",\"plt.xticks(x_pos, xx)\\n\",\"\\n\",\"plt.show()\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\",\"height\":509},\"id\":\"Lj8NZjlIRdLv\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217742872,\"user_tz\":-330,\"elapsed\":716,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"bf34ecdf-0887-4d2c-a63b-6efa76c24652\"},\"execution_count\":5,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"{np.int64(11): 39, np.int64(40): 17, np.int64(38): 115, np.int64(13): 119, np.int64(39): 10, np.int64(4): 70, np.int64(9): 67, np.int64(21): 10, np.int64(2): 111, np.int64(12): 101, np.int64(1): 84, np.int64(25): 34, np.int64(30): 29, np.int64(23): 31, np.int64(27): 6, np.int64(35): 30, np.int64(15): 18, np.int64(33): 31, np.int64(28): 22, np.int64(18): 53, np.int64(36): 18, np.int64(26): 23, np.int64(37): 2, np.int64(34): 24, np.int64(0): 7, np.int64(24): 6, np.int64(14): 49, np.int64(20): 24, np.int64(29): 6, np.int64(6): 33, np.int64(10): 167, np.int64(8): 135, np.int64(5): 69, np.int64(16): 11, np.int64(19): 3, np.int64(17): 75, np.int64(3): 35, np.int64(7): 69, np.int64(41): 13, np.int64(31): 2, np.int64(22): 22, np.int64(42): 15, np.int64(32): 5}\\n\"]},{\"output_type\":\"display_data\",\"data\":{\"text/plain\":[\"<Figure size 640x480 with 1 Axes>\"],\"image/png\":\"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\\n\"},\"metadata\":{}}]},{\"cell_type\":\"code\",\"source\":[\"import sys\\n\",\"sys.path.append('/content/drive/MyDrive/object_detect_gtsdb')\\n\"],\"metadata\":{\"id\":\"-3fid7UJckyO\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217745845,\"user_tz\":-330,\"elapsed\":15,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}}},\"execution_count\":6,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"import torch\\n\",\"import os\\n\",\"from PIL import Image\\n\",\"import torchvision.transforms as T\\n\",\"import pickle\\n\",\"\\n\",\"def analyze_labels(dic):\\n\",\"    \\\"\\\"\\\"\\n\",\"    Analyze all labels in the dataset to understand the label distribution\\n\",\"    \\\"\\\"\\\"\\n\",\"    all_labels = []\\n\",\"\\n\",\"    for key, objects in dic.items():\\n\",\"        for obj in objects:\\n\",\"            label = int(obj[-1])  # Assuming label is the last element\\n\",\"            all_labels.append(label)\\n\",\"\\n\",\"    unique_labels = sorted(set(all_labels))\\n\",\"    label_counts = {label: all_labels.count(label) for label in unique_labels}\\n\",\"\\n\",\"    print(f\\\"Label Analysis:\\\")\\n\",\"    print(f\\\"Total objects: {len(all_labels)}\\\")\\n\",\"    print(f\\\"Unique labels: {len(unique_labels)}\\\")\\n\",\"    print(f\\\"Label range: {min(unique_labels)} to {max(unique_labels)}\\\")\\n\",\"    print(f\\\"Labels: {unique_labels}\\\")\\n\",\"    print(f\\\"Label distribution: {label_counts}\\\")\\n\",\"\\n\",\"    return unique_labels, label_counts\\n\",\"\\n\",\"def create_label_mapping(unique_labels, start_from=1):\\n\",\"    \\\"\\\"\\\"\\n\",\"    Create mapping from original labels to consecutive labels starting from start_from\\n\",\"    For object detection, labels typically start from 1 (0 is reserved for background)\\n\",\"    \\\"\\\"\\\"\\n\",\"    label_mapping = {}\\n\",\"    reverse_mapping = {}\\n\",\"\\n\",\"    for i, original_label in enumerate(sorted(unique_labels)):\\n\",\"        new_label = i + start_from\\n\",\"        label_mapping[original_label] = new_label\\n\",\"        reverse_mapping[new_label] = original_label\\n\",\"\\n\",\"    print(f\\\"\\\\nLabel Mapping (original -> new):\\\")\\n\",\"    for orig, new in label_mapping.items():\\n\",\"        print(f\\\"  {orig} -> {new}\\\")\\n\",\"\\n\",\"    return label_mapping, reverse_mapping\\n\",\"\\n\",\"class myDataset(torch.utils.data.Dataset):\\n\",\"    def __init__(self, root, transforms=None, min_box_size=10, label_mapping=None):\\n\",\"        self.root = root\\n\",\"        self.transforms = transforms\\n\",\"        self.min_box_size = min_box_size\\n\",\"        self.label_mapping = label_mapping or {}  # Mapping from original labels to new labels\\n\",\"        # load all image files, sorting them to ensure that they are aligned\\n\",\"        self.imgs = list(sorted(os.listdir(os.path.join(root, \\\"imagesf\\\"))))\\n\",\"\\n\",\"    def __getitem__(self, idx):\\n\",\"        # Load image path\\n\",\"        img_path = os.path.join(self.root, \\\"imagesf\\\", self.imgs[idx])\\n\",\"        # Load image as PIL\\n\",\"        img = Image.open(img_path).convert(\\\"RGB\\\")\\n\",\"        img_width, img_height = img.size\\n\",\"\\n\",\"        # Get objects in the image\\n\",\"        key = self.imgs[idx]\\n\",\"\\n\",\"        # Check if key exists in dic\\n\",\"        if key not in dic:\\n\",\"            print(f\\\"Warning: Key '{key}' not found in annotations. Skipping...\\\")\\n\",\"            target = {\\n\",\"                \\\"boxes\\\": torch.zeros((0, 4), dtype=torch.float32),\\n\",\"                \\\"labels\\\": torch.zeros(0, dtype=torch.int64),\\n\",\"                \\\"image_id\\\": torch.tensor([idx]),\\n\",\"                \\\"area\\\": torch.zeros(0, dtype=torch.float32),\\n\",\"                \\\"iscrowd\\\": torch.zeros(0, dtype=torch.int64)\\n\",\"            }\\n\",\"            if self.transforms is not None:\\n\",\"                img = self.transforms(img)\\n\",\"            return img, target\\n\",\"\\n\",\"        objects = dic[key]\\n\",\"\\n\",\"        # Get bounding box coordinates for each object in image\\n\",\"        valid_boxes = []\\n\",\"        valid_labels = []\\n\",\"\\n\",\"        for obj in objects:\\n\",\"            original_label = int(obj[-1])\\n\",\"\\n\",\"            # Map label if mapping is provided\\n\",\"            if self.label_mapping:\\n\",\"                if original_label in self.label_mapping:\\n\",\"                    label = self.label_mapping[original_label]\\n\",\"                else:\\n\",\"                    print(f\\\"Warning: Unknown label {original_label} in {key}, skipping object\\\")\\n\",\"                    continue\\n\",\"            else:\\n\",\"                label = original_label\\n\",\"\\n\",\"            # Get bounding box coordinates\\n\",\"            xmin = float(obj[0])\\n\",\"            ymin = float(obj[1])\\n\",\"            xmax = float(obj[2])\\n\",\"            ymax = float(obj[3])\\n\",\"\\n\",\"            # Fix coordinate order if necessary\\n\",\"            if xmin > xmax:\\n\",\"                xmin, xmax = xmax, xmin\\n\",\"\\n\",\"            if ymin > ymax:\\n\",\"                ymin, ymax = ymax, ymin\\n\",\"\\n\",\"            # Clamp coordinates to image boundaries\\n\",\"            xmin = max(0, min(xmin, img_width - 1))\\n\",\"            ymin = max(0, min(ymin, img_height - 1))\\n\",\"            xmax = max(xmin + 1, min(xmax, img_width))\\n\",\"            ymax = max(ymin + 1, min(ymax, img_height))\\n\",\"\\n\",\"            # Check if box is valid\\n\",\"            width = xmax - xmin\\n\",\"            height = ymax - ymin\\n\",\"\\n\",\"            if width >= self.min_box_size and height >= self.min_box_size:\\n\",\"                valid_boxes.append([xmin, ymin, xmax, ymax])\\n\",\"                valid_labels.append(label)\\n\",\"\\n\",\"        # Handle case where no valid boxes remain\\n\",\"        if len(valid_boxes) == 0:\\n\",\"            target = {\\n\",\"                \\\"boxes\\\": torch.zeros((0, 4), dtype=torch.float32),\\n\",\"                \\\"labels\\\": torch.zeros(0, dtype=torch.int64),\\n\",\"                \\\"image_id\\\": torch.tensor([idx]),\\n\",\"                \\\"area\\\": torch.zeros(0, dtype=torch.float32),\\n\",\"                \\\"iscrowd\\\": torch.zeros(0, dtype=torch.int64)\\n\",\"            }\\n\",\"            if self.transforms is not None:\\n\",\"                img = self.transforms(img)\\n\",\"            return img, target\\n\",\"\\n\",\"        boxes = torch.as_tensor(valid_boxes, dtype=torch.float32)\\n\",\"        labels = torch.as_tensor(valid_labels, dtype=torch.int64)\\n\",\"\\n\",\"        image_id = torch.tensor([idx])\\n\",\"        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\\n\",\"        iscrowd = torch.zeros((len(valid_boxes),), dtype=torch.int64)\\n\",\"\\n\",\"        target = {}\\n\",\"        target[\\\"boxes\\\"] = boxes\\n\",\"        target[\\\"labels\\\"] = labels\\n\",\"        target[\\\"image_id\\\"] = image_id\\n\",\"        target[\\\"area\\\"] = area\\n\",\"        target[\\\"iscrowd\\\"] = iscrowd\\n\",\"\\n\",\"        if self.transforms is not None:\\n\",\"            img = self.transforms(img)\\n\",\"\\n\",\"        return img, target\\n\",\"\\n\",\"    def __len__(self):\\n\",\"        return len(self.imgs)\\n\",\"\\n\",\"def get_model_with_correct_classes(num_classes):\\n\",\"    \\\"\\\"\\\"\\n\",\"    Create a model with the correct number of output classes\\n\",\"    \\\"\\\"\\\"\\n\",\"    import torchvision\\n\",\"    from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\\n\",\"\\n\",\"    # Load pre-trained model\\n\",\"    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\\n\",\"\\n\",\"    # Get number of input features for the classifier\\n\",\"    in_features = model.roi_heads.box_predictor.cls_score.in_features\\n\",\"\\n\",\"    # Replace the pre-trained head with a new one\\n\",\"    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\\n\",\"\\n\",\"    return model\\n\",\"\\n\",\"# Usage example:\\n\",\"def setup_dataset_and_model():\\n\",\"    \\\"\\\"\\\"\\n\",\"    Complete setup function to analyze labels and create proper dataset/model\\n\",\"    \\\"\\\"\\\"\\n\",\"    # 1. Analyze labels in your data\\n\",\"    unique_labels, label_counts = analyze_labels(dic)\\n\",\"\\n\",\"    # 2. Create label mapping (starting from 1, as 0 is background in object detection)\\n\",\"    label_mapping, reverse_mapping = create_label_mapping(unique_labels, start_from=1)\\n\",\"\\n\",\"    # 3. Calculate number of classes (including background class 0)\\n\",\"    num_classes = len(unique_labels) + 1  # +1 for background\\n\",\"    print(f\\\"\\\\nModel will be created with {num_classes} classes\\\")\\n\",\"\\n\",\"    # 4. Create model with correct number of classes\\n\",\"    model = get_model_with_correct_classes(num_classes)\\n\",\"\\n\",\"    # 5. Create dataset with label mapping\\n\",\"    transforms = T.Compose([\\n\",\"        T.ToTensor(),\\n\",\"        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\\n\",\"    ])\\n\",\"\\n\",\"    train_dataset = myDataset('your_root_path', transforms=transforms, label_mapping=label_mapping)\\n\",\"\\n\",\"    return model, train_dataset, label_mapping, reverse_mapping, num_classes\\n\",\"\\n\",\"# Save label mapping for later use\\n\",\"def save_label_mapping(label_mapping, reverse_mapping, filename=\\\"label_mapping.pkl\\\"):\\n\",\"    mapping_data = {\\n\",\"        'label_mapping': label_mapping,  # original -> new\\n\",\"        'reverse_mapping': reverse_mapping,  # new -> original\\n\",\"        'num_classes': len(label_mapping) + 1  # +1 for background\\n\",\"    }\\n\",\"\\n\",\"    with open(filename, 'wb') as f:\\n\",\"        pickle.dump(mapping_data, f)\\n\",\"\\n\",\"    print(f\\\"Label mapping saved to {filename}\\\")\\n\",\"    return mapping_data\"],\"metadata\":{\"id\":\"e0RvZK3SLQY5\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217746775,\"user_tz\":-330,\"elapsed\":31,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}}},\"execution_count\":7,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"dic = {}\\n\",\"root = r'/content/drive/MyDrive/object_detect_gtsdb'\\n\",\"with open(os.path.join(root, \\\"gt.txt\\\")) as f:\\n\",\"    for line in f:\\n\",\"        parts = line.strip().split(';')\\n\",\"        fname = parts[0]  # '00000.ppm'\\n\",\"        class_id = int(parts[1])\\n\",\"        bbox = list(map(int, parts[2:]))  # [x1, y1, x2, y2]\\n\",\"\\n\",\"        if fname not in dic:\\n\",\"            dic[fname] = []\\n\",\"\\n\",\"        dic[fname].append([*bbox, class_id])\"],\"metadata\":{\"id\":\"kdzIhoCNN1UA\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217753547,\"user_tz\":-330,\"elapsed\":42,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}}},\"execution_count\":8,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"# Step 1: Mount Drive\\n\",\"from google.colab import drive\\n\",\"drive.mount('/content/drive')\\n\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"aWrAVfm8SyRs\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217756982,\"user_tz\":-330,\"elapsed\":1769,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"70010b3f-e264-4216-d41f-cd838186f767\"},\"execution_count\":9,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\\\"/content/drive\\\", force_remount=True).\\n\"]}]},{\"cell_type\":\"code\",\"source\":[],\"metadata\":{\"id\":\"LBf5xmEmS8BV\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754215160912,\"user_tz\":-330,\"elapsed\":31,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}}},\"execution_count\":75,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"# Step 2: Go to your working directory\\n\",\"%cd /content/drive/MyDrive/object_detect_gtsdb\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"6IGNBYxdS0JM\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217757604,\"user_tz\":-330,\"elapsed\":17,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"7ec1275f-a3a6-4f9a-d22f-4e045eb70ee2\"},\"execution_count\":10,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"/content/drive/MyDrive/object_detect_gtsdb\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"# Step 3: Add the parent folder to Python path\\n\",\"import sys\\n\",\"sys.path.append('/content/drive/MyDrive/object_detect_gtsdb')\"],\"metadata\":{\"id\":\"WgjQYUvYS9RM\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217759207,\"user_tz\":-330,\"elapsed\":26,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}}},\"execution_count\":11,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"import os\\n\",\"print(os.listdir('./util'))\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"-AWkQ5S9TEF_\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217760265,\"user_tz\":-330,\"elapsed\":34,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"16287b03-1fac-43ae-9b3e-ee0f370bc9f3\"},\"execution_count\":12,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"['box_ops.py', 'plot_utils.py', 'misc.py', '__init__.py', '__pycache__']\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"from util import misc\\n\"],\"metadata\":{\"id\":\"ztsxgt9nTqJl\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217762948,\"user_tz\":-330,\"elapsed\":4,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}}},\"execution_count\":13,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"import sys\\n\",\"sys.path.append('/content/drive/MyDrive/object_detect_gtsdb')\\n\",\"%cd /content/drive/MyDrive/object_detect_gtsdb\\n\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"MJFdT0erSMGh\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217763962,\"user_tz\":-330,\"elapsed\":65,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"e4b821f5-a86b-4c5e-b96f-44b32482badc\"},\"execution_count\":14,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"/content/drive/MyDrive/object_detect_gtsdb\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"# Step 4: Ensure util is a package\\n\",\"!touch util/__init__.py\\n\"],\"metadata\":{\"id\":\"NpllXaj9QHoQ\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217765228,\"user_tz\":-330,\"elapsed\":164,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}}},\"execution_count\":15,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"!ls datasets\\n\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"f8bFtYbLUg7S\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217766435,\"user_tz\":-330,\"elapsed\":118,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"e87fb6ee-5163-46da-effb-ea4bba81de8a\"},\"execution_count\":16,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"ls: cannot access 'datasets': No such file or directory\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"%cd /content/drive/MyDrive/object_detect_gtsdb\\n\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"xTchte9MUlKK\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217768104,\"user_tz\":-330,\"elapsed\":13,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"3e755050-49cd-4741-b522-d48243d9542a\"},\"execution_count\":17,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"/content/drive/MyDrive/object_detect_gtsdb\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"import sys\\n\",\"sys.path.insert(0, '/content/drive/MyDrive/object_detect_gtsdb')\\n\"],\"metadata\":{\"id\":\"nynHzSDwUphr\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217769019,\"user_tz\":-330,\"elapsed\":5,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}}},\"execution_count\":18,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"!ls my_datasets\\n\",\"print(sys.path)\\n\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"PWSUEzg7YdK0\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217769910,\"user_tz\":-330,\"elapsed\":175,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"9fa0879f-9e06-4c53-c751-f375d9a0af17\"},\"execution_count\":19,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"coco_eval.py\\t  coco.py      panoptic_eval.py  transforms.py\\n\",\"coco_panoptic.py  __init__.py  __pycache__\\n\",\"['/content/drive/MyDrive/object_detect_gtsdb', '/content', '/env/python', '/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '', '/usr/local/lib/python3.11/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.11/dist-packages/IPython/extensions', '/root/.ipython', '/usr/local/lib/python3.11/dist-packages/setuptools/_vendor', '/tmp/tmp7jwni8ad', '/content/drive/MyDrive/object_detect_gtsdb', '/content/drive/MyDrive/object_detect_gtsdb', '/content/drive/MyDrive/object_detect_gtsdb']\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"!find . -name coco_eval.py\\n\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"9GQxoUOHYqe_\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217771229,\"user_tz\":-330,\"elapsed\":152,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"8f6cf4f7-ba13-42ca-bcf2-41c3aad45f0a\"},\"execution_count\":20,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"./my_datasets/coco_eval.py\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"import sys\\n\",\"sys.path.append('/content/drive/MyDrive/object_detect_gtsdb')\\n\",\"from my_datasets import coco_eval\"],\"metadata\":{\"id\":\"vezw7e0fUMcQ\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217772634,\"user_tz\":-330,\"elapsed\":4,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}}},\"execution_count\":21,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"!ls /content/drive/MyDrive/object_detect_gtsdb/my_datasets\\n\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"nQBVKO4AZNQa\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217773765,\"user_tz\":-330,\"elapsed\":113,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"49add06a-4d5f-4bf9-feda-2f753822c6f9\"},\"execution_count\":22,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"coco_eval.py\\t  coco.py      panoptic_eval.py  transforms.py\\n\",\"coco_panoptic.py  __init__.py  __pycache__\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"import engine  # This should now work\\n\"],\"metadata\":{\"id\":\"2MDUGtU-SqQ0\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217775066,\"user_tz\":-330,\"elapsed\":17,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}}},\"execution_count\":23,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"import sys\\n\",\"sys.path.append('/content/drive/MyDrive/object_detect_gtsdb')  # Don't include a comma or parentheses here\\n\",\"import sys\\n\",\"sys.path.append('/content/drive/MyDrive/object_detect_gtsdb')\\n\",\"print(sys.path[-1])  # Confirm it's a string\\n\",\"\\n\",\"import os\\n\",\"print(os.path.isfile('/content/drive/MyDrive/object_detect_gtsdb/my_utils.py'))\\n\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"vc5QKeqsbHvJ\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217776076,\"user_tz\":-330,\"elapsed\":29,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"6bf47f87-94ca-4660-e0fb-51129746fb68\"},\"execution_count\":24,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"/content/drive/MyDrive/object_detect_gtsdb\\n\",\"True\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"!head -n 15 /content/drive/MyDrive/object_detect_gtsdb/my_utils.py\\n\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"W4r6PlhHgv81\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217778817,\"user_tz\":-330,\"elapsed\":543,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"585688b8-ccd0-4212-b862-5b87249d5cc7\"},\"execution_count\":25,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"import datetime\\n\",\"import errno\\n\",\"import os\\n\",\"import time\\n\",\"from collections import defaultdict, deque\\n\",\"\\n\",\"import torch\\n\",\"import torch.distributed as dist\\n\",\"\\n\",\"\\n\",\"class SmoothedValue:\\n\",\"    \\\"\\\"\\\"Track a series of values and provide access to smoothed values over a\\n\",\"    window or the global series average.\\n\",\"    \\\"\\\"\\\"\\n\",\"\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"import sys\\n\",\"sys.path.append('/content/drive/MyDrive/object_detect_gtsdb')\\n\",\"\\n\",\"# Now you can import engine.py like this:\\n\",\"import engine\"],\"metadata\":{\"id\":\"E_DFMTSrP6rW\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217781441,\"user_tz\":-330,\"elapsed\":31,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}}},\"execution_count\":26,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[],\"metadata\":{\"id\":\"mpIP8gbBQp0C\"},\"execution_count\":null,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"import my_utils\\n\",\"from torchvision import transforms as T\\n\",\"from engine import train_one_epoch, evaluate\\n\",\"# utils, transforms, engine were just downloadedUtils.py,transforms.py,engine.py\\n\",\"\\n\",\"def get_transform(train):\\n\",\"    transforms = []\\n\",\"    # converts the image, a PIL image, into a PyTorch Tensor\\n\",\"    transforms.append(T.ToTensor())\\n\",\"    if train:\\n\",\"        # during training, randomly flip the training images\\n\",\"        # and ground-truth for data augmentation\\n\",\"        # 50% chance of flipping horizontally\\n\",\"        transforms.append(T.RandomHorizontalFlip(0.5))\\n\",\"\\n\",\"    return T.Compose(transforms)\"],\"metadata\":{\"id\":\"S1J6A6mROzj4\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217784058,\"user_tz\":-330,\"elapsed\":39,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}}},\"execution_count\":27,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"import sys\\n\",\"sys.path.append('/content/drive/MyDrive/object_detect_gtsdb')\\n\"],\"metadata\":{\"id\":\"QI_3B_Okcar0\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217786787,\"user_tz\":-330,\"elapsed\":9,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}}},\"execution_count\":28,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"import my_utils\"],\"metadata\":{\"id\":\"EUhKGPSscfbJ\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217790834,\"user_tz\":-330,\"elapsed\":10,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}}},\"execution_count\":29,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"from engine import train_one_epoch, evaluate\\n\",\"import my_utils\\n\",\"import torch.nn as nn\\n\",\"\\n\",\"\\n\",\"\\n\",\"os.environ['TORCH_HOME'] = './'\\n\",\"\\n\",\"root = r'/content/drive/MyDrive/object_detect_gtsdb'\\n\",\"\\n\",\"# Train on the GPU if available else CPU.\\n\",\"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\\n\",\"\\n\",\"# 44 classes = 43 + background\\n\",\"num_classes = 44\\n\",\"#Send the data to the myDataset class (Apply transformations, Get bbox, labels, objects)\\n\",\"dataset = myDataset(root, get_transform(train=True))\\n\",\"dataset_test = myDataset(root, get_transform(train=False))\\n\",\"\\n\",\"# split the dataset in train and test set\\n\",\"# My dataset has 506 images, almost training validation 4:1\\n\",\"indices = torch.randperm(len(dataset)).tolist()\\n\",\"dataset = torch.utils.data.Subset(dataset, indices[:-100])\\n\",\"dataset_test = torch.utils.data.Subset(dataset_test, indices[-100:])\\n\",\"\\n\",\"# define training and validation data loaders\\n\",\"#collate_fn returns tuples of images and image annotations for every iteration.\\n\",\"data_loader = torch.utils.data.DataLoader(\\n\",\"    dataset, batch_size=2, shuffle=True, # num_workers=4,\\n\",\"    collate_fn=my_utils.collate_fn)\\n\",\"\\n\",\"data_loader_test = torch.utils.data.DataLoader(\\n\",\"    dataset_test, batch_size=2, shuffle=False, # num_workers=4,\\n\",\"    collate_fn=my_utils.collate_fn)\\n\",\"\\n\",\"# Define model\\n\",\"model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, progress=True, num_classes=num_classes, pretrained_backbone=True)\\n\",\"# OR model = get_object_detection_model(num_classes)\\n\",\"#model = torch.load('./train150.pkl')\\n\",\"\\n\",\"#Use specific GPUs:\\n\",\"#Remove this line if not necessary.\\n\",\"\\n\",\"# Move the model to device\\n\",\"model.to(device)\\n\",\"\\n\",\"print(\\\"Model loaded\\\")\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"ezDtIqe6ax7Z\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217855360,\"user_tz\":-330,\"elapsed\":891,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"9779683c-52c6-4fb7-f498-a3546924f85a\"},\"execution_count\":31,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Model loaded\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"import my_utils\\n\",\"print(utils.__file__)\\n\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"EsnFlxUKd_lY\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754216793518,\"user_tz\":-330,\"elapsed\":48,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"7521c3d2-0a06-46e7-a9ea-c466d3d2dafa\"},\"execution_count\":30,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"/usr/local/lib/python3.11/dist-packages/utils/__init__.py\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"import torch\\n\",\"import torchvision\\n\",\"from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\\n\",\"import torchvision.transforms as T\\n\",\"from torch.utils.data import DataLoader\\n\",\"import pickle\\n\",\"\\n\",\"# Step 1: Analyze your labels and create mapping\\n\",\"print(\\\"Step 1: Analyzing labels...\\\")\\n\",\"unique_labels, label_counts = analyze_labels(dic)\\n\",\"\\n\",\"# Step 2: Create label mapping\\n\",\"print(\\\"\\\\nStep 2: Creating label mapping...\\\")\\n\",\"label_mapping, reverse_mapping = create_label_mapping(unique_labels, start_from=1)\\n\",\"\\n\",\"# Step 3: Calculate number of classes\\n\",\"num_classes = len(unique_labels) + 1  # +1 for background\\n\",\"print(f\\\"\\\\nStep 3: Number of classes (including background): {num_classes}\\\")\\n\",\"\\n\",\"# Step 4: Create model with correct number of classes\\n\",\"print(f\\\"\\\\nStep 4: Creating model...\\\")\\n\",\"model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\\n\",\"in_features = model.roi_heads.box_predictor.cls_score.in_features\\n\",\"model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\\n\",\"\\n\",\"# Move model to device\\n\",\"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\\n\",\"model.to(device)\\n\",\"\\n\",\"# Step 5: Create datasets with label mapping\\n\",\"print(f\\\"\\\\nStep 5: Creating datasets...\\\")\\n\",\"def get_transforms(train=True):\\n\",\"    transforms = [T.ToTensor()]\\n\",\"    if train:\\n\",\"        # Add data augmentation for training\\n\",\"        transforms.append(T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1))\\n\",\"    transforms.append(T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]))\\n\",\"    return T.Compose(transforms)\\n\",\"\\n\",\"# Update your root path here\\n\",\"root_path = r'/content/drive/MyDrive/object_detect_gtsdb'\\n\",\"\\n\",\"train_dataset = myDataset(root_path,\\n\",\"                         transforms=get_transforms(train=True),\\n\",\"                         label_mapping=label_mapping)\\n\",\"\\n\",\"test_dataset = myDataset(root_path,\\n\",\"                        transforms=get_transforms(train=False),\\n\",\"                        label_mapping=label_mapping)\\n\",\"\\n\",\"# Step 6: Create data loaders\\n\",\"def collate_fn(batch):\\n\",\"    return tuple(zip(*batch))\\n\",\"\\n\",\"train_loader = DataLoader(train_dataset,\\n\",\"                         batch_size=4,\\n\",\"                         shuffle=True,\\n\",\"                         collate_fn=collate_fn,\\n\",\"                         num_workers=0)  # Set to 0 if having issues with multiprocessing\\n\",\"\\n\",\"test_loader = DataLoader(test_dataset,\\n\",\"                        batch_size=1,\\n\",\"                        shuffle=False,\\n\",\"                        collate_fn=collate_fn,\\n\",\"                        num_workers=0)\\n\",\"\\n\",\"# Step 7: Setup training\\n\",\"print(f\\\"\\\\nStep 7: Setting up training...\\\")\\n\",\"params = [p for p in model.parameters() if p.requires_grad]\\n\",\"optimizer = torch.optim.SGD(params, lr=0.0005, momentum=0.9, weight_decay=0.0005)\\n\",\"lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=2)\\n\",\"\\n\",\"# Step 8: Save label mapping for future use\\n\",\"save_label_mapping(label_mapping, reverse_mapping, \\\"label_mapping.pkl\\\")\\n\",\"\\n\",\"print(f\\\"\\\\nSetup complete!\\\")\\n\",\"print(f\\\"- Original labels: {unique_labels}\\\")\\n\",\"print(f\\\"- Mapped labels: {list(range(1, num_classes))}\\\")\\n\",\"print(f\\\"- Total classes (including background): {num_classes}\\\")\\n\",\"print(f\\\"- Training samples: {len(train_dataset)}\\\")\\n\",\"print(f\\\"- Test samples: {len(test_dataset)}\\\")\\n\",\"\\n\",\"# Step 9: Test the data loader\\n\",\"print(f\\\"\\\\nStep 9: Testing data loader...\\\")\\n\",\"try:\\n\",\"    images, targets = next(iter(train_loader))\\n\",\"    print(f\\\" Data loader working correctly!\\\")\\n\",\"    print(f\\\"  Batch size: {len(images)}\\\")\\n\",\"    if len(targets) > 0 and len(targets[0]['labels']) > 0:\\n\",\"        print(f\\\"  Sample labels in batch: {targets[0]['labels'].tolist()}\\\")\\n\",\"except Exception as e:\\n\",\"    print(f\\\" Data loader error: {e}\\\")\\n\",\"\\n\",\"# Now you can use train_loader and test_loader for training\\n\",\"data_loader = train_loader\\n\",\"data_loader_test = test_loader\\n\",\"\\n\",\"print(f\\\"\\\\nYou can now start training with:\\\")\\n\",\"print(f\\\"- model: {type(model).__name__}\\\")\\n\",\"print(f\\\"- data_loader: {len(data_loader)} batches\\\")\\n\",\"print(f\\\"- data_loader_test: {len(data_loader_test)} batches\\\")\\n\",\"print(f\\\"- device: {device}\\\")\\n\",\"\\n\",\"# Your training loop can now proceed...\\n\",\"# from engine import train_one_epoch, evaluate\\n\",\"# metrics = train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=50)\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"cMSCkN1KiHv7\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754217982365,\"user_tz\":-330,\"elapsed\":4244,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"f1fce63a-a8cd-4116-e990-92f369db3f58\"},\"execution_count\":33,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Step 1: Analyzing labels...\\n\",\"Label Analysis:\\n\",\"Total objects: 852\\n\",\"Unique labels: 608\\n\",\"Label range: 22 to 1305\\n\",\"Labels: [22, 23, 27, 28, 29, 46, 53, 55, 56, 57, 58, 61, 69, 86, 91, 98, 99, 100, 101, 102, 107, 109, 110, 112, 113, 116, 120, 122, 124, 128, 138, 142, 148, 150, 157, 161, 163, 164, 166, 167, 172, 175, 178, 180, 183, 185, 186, 187, 192, 198, 201, 203, 204, 206, 209, 212, 213, 218, 224, 229, 230, 233, 235, 236, 237, 239, 240, 241, 242, 243, 244, 247, 248, 249, 252, 253, 256, 257, 259, 260, 262, 264, 266, 267, 271, 273, 275, 278, 283, 284, 285, 288, 290, 291, 293, 294, 296, 297, 298, 302, 306, 307, 310, 311, 312, 314, 315, 316, 318, 323, 325, 327, 330, 335, 338, 339, 341, 344, 346, 350, 351, 353, 354, 355, 358, 359, 361, 365, 366, 367, 369, 377, 378, 379, 380, 381, 382, 383, 386, 389, 391, 392, 394, 396, 398, 401, 403, 407, 409, 410, 411, 412, 413, 420, 421, 423, 425, 430, 432, 438, 439, 440, 442, 445, 446, 451, 453, 454, 455, 456, 457, 458, 460, 461, 463, 467, 470, 471, 474, 475, 477, 483, 484, 486, 490, 491, 492, 494, 496, 500, 502, 504, 505, 507, 509, 510, 511, 514, 517, 518, 519, 520, 521, 527, 528, 532, 533, 534, 537, 538, 544, 549, 551, 553, 555, 558, 568, 569, 575, 579, 581, 584, 589, 593, 594, 597, 599, 601, 602, 603, 605, 610, 616, 617, 625, 627, 631, 634, 638, 644, 646, 648, 650, 655, 656, 657, 658, 662, 667, 668, 670, 671, 675, 677, 678, 680, 681, 683, 686, 689, 692, 693, 695, 696, 698, 699, 700, 702, 703, 705, 707, 708, 710, 711, 712, 713, 717, 718, 720, 721, 723, 724, 726, 727, 728, 729, 730, 731, 732, 734, 737, 742, 744, 745, 746, 750, 752, 753, 755, 756, 758, 760, 762, 763, 765, 766, 767, 769, 770, 771, 772, 774, 775, 779, 780, 782, 783, 784, 785, 786, 788, 789, 790, 792, 793, 794, 795, 798, 799, 800, 801, 802, 805, 808, 812, 813, 814, 815, 816, 817, 819, 822, 823, 824, 825, 826, 827, 828, 829, 831, 833, 834, 835, 836, 838, 839, 840, 841, 842, 843, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 863, 865, 866, 867, 868, 869, 870, 872, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 890, 891, 892, 893, 894, 895, 898, 900, 901, 902, 903, 904, 906, 907, 908, 909, 910, 912, 913, 915, 916, 921, 922, 923, 925, 926, 929, 932, 933, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 949, 950, 951, 952, 953, 956, 958, 962, 964, 965, 966, 967, 968, 969, 971, 972, 973, 974, 975, 976, 977, 979, 980, 982, 983, 984, 985, 988, 989, 990, 993, 994, 995, 997, 998, 999, 1000, 1002, 1008, 1009, 1010, 1011, 1015, 1017, 1019, 1021, 1025, 1028, 1032, 1036, 1038, 1039, 1040, 1042, 1043, 1045, 1046, 1047, 1048, 1050, 1051, 1052, 1054, 1055, 1056, 1062, 1063, 1064, 1071, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1089, 1090, 1091, 1092, 1094, 1095, 1097, 1101, 1104, 1105, 1110, 1111, 1113, 1117, 1120, 1122, 1123, 1125, 1127, 1128, 1129, 1131, 1132, 1133, 1135, 1138, 1139, 1140, 1141, 1143, 1144, 1146, 1147, 1150, 1151, 1152, 1156, 1159, 1166, 1168, 1169, 1172, 1173, 1177, 1182, 1185, 1186, 1193, 1194, 1195, 1196, 1199, 1201, 1202, 1205, 1206, 1209, 1211, 1212, 1213, 1214, 1215, 1219, 1220, 1223, 1224, 1226, 1227, 1228, 1229, 1231, 1233, 1236, 1237, 1238, 1241, 1242, 1243, 1244, 1245, 1249, 1255, 1260, 1264, 1267, 1271, 1273, 1274, 1282, 1285, 1287, 1294, 1295, 1302, 1305]\\n\",\"Label distribution: {22: 2, 23: 1, 27: 1, 28: 1, 29: 1, 46: 1, 53: 1, 55: 1, 56: 1, 57: 1, 58: 1, 61: 1, 69: 1, 86: 1, 91: 1, 98: 1, 99: 1, 100: 1, 101: 1, 102: 1, 107: 1, 109: 1, 110: 2, 112: 1, 113: 1, 116: 2, 120: 1, 122: 1, 124: 1, 128: 1, 138: 1, 142: 1, 148: 1, 150: 1, 157: 1, 161: 1, 163: 1, 164: 1, 166: 1, 167: 1, 172: 1, 175: 1, 178: 1, 180: 1, 183: 1, 185: 2, 186: 1, 187: 1, 192: 1, 198: 1, 201: 1, 203: 1, 204: 1, 206: 1, 209: 1, 212: 1, 213: 2, 218: 1, 224: 1, 229: 1, 230: 2, 233: 1, 235: 1, 236: 1, 237: 1, 239: 1, 240: 1, 241: 1, 242: 1, 243: 1, 244: 1, 247: 2, 248: 1, 249: 2, 252: 1, 253: 1, 256: 1, 257: 2, 259: 1, 260: 1, 262: 1, 264: 1, 266: 1, 267: 1, 271: 2, 273: 1, 275: 1, 278: 1, 283: 1, 284: 1, 285: 2, 288: 1, 290: 1, 291: 1, 293: 1, 294: 1, 296: 1, 297: 1, 298: 1, 302: 2, 306: 1, 307: 1, 310: 1, 311: 1, 312: 1, 314: 2, 315: 1, 316: 2, 318: 1, 323: 1, 325: 3, 327: 1, 330: 1, 335: 1, 338: 1, 339: 1, 341: 1, 344: 1, 346: 1, 350: 1, 351: 1, 353: 1, 354: 1, 355: 1, 358: 1, 359: 1, 361: 1, 365: 1, 366: 1, 367: 1, 369: 2, 377: 1, 378: 1, 379: 3, 380: 1, 381: 1, 382: 2, 383: 2, 386: 1, 389: 1, 391: 1, 392: 1, 394: 1, 396: 1, 398: 1, 401: 1, 403: 1, 407: 1, 409: 1, 410: 2, 411: 1, 412: 1, 413: 2, 420: 2, 421: 1, 423: 1, 425: 3, 430: 2, 432: 1, 438: 1, 439: 1, 440: 1, 442: 1, 445: 1, 446: 1, 451: 1, 453: 1, 454: 1, 455: 3, 456: 2, 457: 1, 458: 1, 460: 2, 461: 1, 463: 1, 467: 1, 470: 1, 471: 1, 474: 2, 475: 1, 477: 2, 483: 1, 484: 1, 486: 1, 490: 1, 491: 1, 492: 1, 494: 1, 496: 1, 500: 1, 502: 1, 504: 2, 505: 2, 507: 1, 509: 3, 510: 1, 511: 2, 514: 2, 517: 2, 518: 1, 519: 2, 520: 2, 521: 1, 527: 1, 528: 1, 532: 1, 533: 1, 534: 1, 537: 1, 538: 1, 544: 1, 549: 1, 551: 2, 553: 1, 555: 2, 558: 1, 568: 2, 569: 2, 575: 1, 579: 1, 581: 1, 584: 1, 589: 1, 593: 1, 594: 1, 597: 1, 599: 1, 601: 1, 602: 1, 603: 1, 605: 1, 610: 2, 616: 1, 617: 1, 625: 1, 627: 1, 631: 1, 634: 1, 638: 1, 644: 1, 646: 1, 648: 1, 650: 1, 655: 1, 656: 1, 657: 2, 658: 1, 662: 1, 667: 2, 668: 1, 670: 1, 671: 1, 675: 1, 677: 1, 678: 3, 680: 1, 681: 1, 683: 1, 686: 1, 689: 1, 692: 1, 693: 3, 695: 2, 696: 1, 698: 1, 699: 1, 700: 1, 702: 1, 703: 1, 705: 1, 707: 2, 708: 1, 710: 1, 711: 1, 712: 2, 713: 2, 717: 1, 718: 5, 720: 2, 721: 1, 723: 2, 724: 1, 726: 1, 727: 3, 728: 1, 729: 2, 730: 1, 731: 2, 732: 1, 734: 2, 737: 1, 742: 2, 744: 1, 745: 1, 746: 1, 750: 1, 752: 1, 753: 2, 755: 1, 756: 1, 758: 1, 760: 1, 762: 2, 763: 1, 765: 1, 766: 2, 767: 2, 769: 1, 770: 1, 771: 2, 772: 1, 774: 2, 775: 2, 779: 3, 780: 1, 782: 1, 783: 1, 784: 3, 785: 1, 786: 2, 788: 2, 789: 2, 790: 2, 792: 1, 793: 2, 794: 4, 795: 1, 798: 1, 799: 1, 800: 2, 801: 1, 802: 1, 805: 1, 808: 1, 812: 1, 813: 1, 814: 2, 815: 2, 816: 3, 817: 2, 819: 3, 822: 1, 823: 2, 824: 2, 825: 3, 826: 2, 827: 6, 828: 1, 829: 4, 831: 1, 833: 2, 834: 2, 835: 1, 836: 2, 838: 2, 839: 1, 840: 2, 841: 2, 842: 3, 843: 2, 845: 1, 846: 1, 847: 4, 848: 1, 849: 3, 850: 2, 851: 1, 852: 1, 853: 1, 854: 1, 855: 1, 856: 2, 857: 1, 858: 1, 859: 1, 863: 1, 865: 1, 866: 2, 867: 1, 868: 1, 869: 2, 870: 1, 872: 1, 874: 3, 875: 1, 876: 1, 877: 1, 878: 1, 879: 1, 880: 3, 881: 1, 882: 1, 883: 3, 884: 1, 885: 1, 886: 1, 890: 1, 891: 1, 892: 2, 893: 2, 894: 1, 895: 1, 898: 1, 900: 1, 901: 2, 902: 1, 903: 2, 904: 1, 906: 1, 907: 2, 908: 2, 909: 1, 910: 3, 912: 2, 913: 1, 915: 2, 916: 1, 921: 2, 922: 1, 923: 2, 925: 1, 926: 1, 929: 3, 932: 1, 933: 1, 937: 3, 938: 1, 939: 1, 940: 1, 941: 1, 942: 1, 943: 1, 944: 1, 945: 2, 946: 6, 947: 2, 949: 2, 950: 1, 951: 1, 952: 3, 953: 2, 956: 2, 958: 1, 962: 2, 964: 2, 965: 1, 966: 3, 967: 1, 968: 3, 969: 3, 971: 1, 972: 1, 973: 2, 974: 4, 975: 1, 976: 1, 977: 3, 979: 2, 980: 1, 982: 3, 983: 2, 984: 1, 985: 3, 988: 4, 989: 2, 990: 4, 993: 2, 994: 1, 995: 1, 997: 1, 998: 3, 999: 1, 1000: 1, 1002: 2, 1008: 1, 1009: 2, 1010: 2, 1011: 1, 1015: 2, 1017: 2, 1019: 1, 1021: 1, 1025: 1, 1028: 2, 1032: 2, 1036: 1, 1038: 1, 1039: 1, 1040: 2, 1042: 1, 1043: 1, 1045: 1, 1046: 1, 1047: 2, 1048: 1, 1050: 2, 1051: 1, 1052: 1, 1054: 3, 1055: 2, 1056: 1, 1062: 2, 1063: 1, 1064: 1, 1071: 1, 1075: 1, 1076: 1, 1077: 1, 1078: 1, 1079: 1, 1080: 2, 1081: 1, 1082: 1, 1089: 2, 1090: 1, 1091: 4, 1092: 1, 1094: 2, 1095: 1, 1097: 1, 1101: 1, 1104: 1, 1105: 1, 1110: 2, 1111: 1, 1113: 3, 1117: 1, 1120: 2, 1122: 2, 1123: 1, 1125: 1, 1127: 1, 1128: 1, 1129: 1, 1131: 3, 1132: 2, 1133: 3, 1135: 1, 1138: 1, 1139: 1, 1140: 1, 1141: 1, 1143: 1, 1144: 1, 1146: 1, 1147: 1, 1150: 2, 1151: 1, 1152: 3, 1156: 1, 1159: 2, 1166: 1, 1168: 1, 1169: 1, 1172: 2, 1173: 1, 1177: 1, 1182: 2, 1185: 2, 1186: 3, 1193: 1, 1194: 1, 1195: 2, 1196: 1, 1199: 1, 1201: 1, 1202: 3, 1205: 1, 1206: 1, 1209: 1, 1211: 2, 1212: 1, 1213: 1, 1214: 1, 1215: 2, 1219: 2, 1220: 1, 1223: 1, 1224: 1, 1226: 2, 1227: 1, 1228: 1, 1229: 1, 1231: 1, 1233: 1, 1236: 1, 1237: 3, 1238: 3, 1241: 1, 1242: 1, 1243: 2, 1244: 1, 1245: 1, 1249: 1, 1255: 2, 1260: 1, 1264: 1, 1267: 1, 1271: 1, 1273: 1, 1274: 1, 1282: 2, 1285: 1, 1287: 1, 1294: 1, 1295: 1, 1302: 1, 1305: 1}\\n\",\"\\n\",\"Step 2: Creating label mapping...\\n\",\"\\n\",\"Label Mapping (original -> new):\\n\",\"  22 -> 1\\n\",\"  23 -> 2\\n\",\"  27 -> 3\\n\",\"  28 -> 4\\n\",\"  29 -> 5\\n\",\"  46 -> 6\\n\",\"  53 -> 7\\n\",\"  55 -> 8\\n\",\"  56 -> 9\\n\",\"  57 -> 10\\n\",\"  58 -> 11\\n\",\"  61 -> 12\\n\",\"  69 -> 13\\n\",\"  86 -> 14\\n\",\"  91 -> 15\\n\",\"  98 -> 16\\n\",\"  99 -> 17\\n\",\"  100 -> 18\\n\",\"  101 -> 19\\n\",\"  102 -> 20\\n\",\"  107 -> 21\\n\",\"  109 -> 22\\n\",\"  110 -> 23\\n\",\"  112 -> 24\\n\",\"  113 -> 25\\n\",\"  116 -> 26\\n\",\"  120 -> 27\\n\",\"  122 -> 28\\n\",\"  124 -> 29\\n\",\"  128 -> 30\\n\",\"  138 -> 31\\n\",\"  142 -> 32\\n\",\"  148 -> 33\\n\",\"  150 -> 34\\n\",\"  157 -> 35\\n\",\"  161 -> 36\\n\",\"  163 -> 37\\n\",\"  164 -> 38\\n\",\"  166 -> 39\\n\",\"  167 -> 40\\n\",\"  172 -> 41\\n\",\"  175 -> 42\\n\",\"  178 -> 43\\n\",\"  180 -> 44\\n\",\"  183 -> 45\\n\",\"  185 -> 46\\n\",\"  186 -> 47\\n\",\"  187 -> 48\\n\",\"  192 -> 49\\n\",\"  198 -> 50\\n\",\"  201 -> 51\\n\",\"  203 -> 52\\n\",\"  204 -> 53\\n\",\"  206 -> 54\\n\",\"  209 -> 55\\n\",\"  212 -> 56\\n\",\"  213 -> 57\\n\",\"  218 -> 58\\n\",\"  224 -> 59\\n\",\"  229 -> 60\\n\",\"  230 -> 61\\n\",\"  233 -> 62\\n\",\"  235 -> 63\\n\",\"  236 -> 64\\n\",\"  237 -> 65\\n\",\"  239 -> 66\\n\",\"  240 -> 67\\n\",\"  241 -> 68\\n\",\"  242 -> 69\\n\",\"  243 -> 70\\n\",\"  244 -> 71\\n\",\"  247 -> 72\\n\",\"  248 -> 73\\n\",\"  249 -> 74\\n\",\"  252 -> 75\\n\",\"  253 -> 76\\n\",\"  256 -> 77\\n\",\"  257 -> 78\\n\",\"  259 -> 79\\n\",\"  260 -> 80\\n\",\"  262 -> 81\\n\",\"  264 -> 82\\n\",\"  266 -> 83\\n\",\"  267 -> 84\\n\",\"  271 -> 85\\n\",\"  273 -> 86\\n\",\"  275 -> 87\\n\",\"  278 -> 88\\n\",\"  283 -> 89\\n\",\"  284 -> 90\\n\",\"  285 -> 91\\n\",\"  288 -> 92\\n\",\"  290 -> 93\\n\",\"  291 -> 94\\n\",\"  293 -> 95\\n\",\"  294 -> 96\\n\",\"  296 -> 97\\n\",\"  297 -> 98\\n\",\"  298 -> 99\\n\",\"  302 -> 100\\n\",\"  306 -> 101\\n\",\"  307 -> 102\\n\",\"  310 -> 103\\n\",\"  311 -> 104\\n\",\"  312 -> 105\\n\",\"  314 -> 106\\n\",\"  315 -> 107\\n\",\"  316 -> 108\\n\",\"  318 -> 109\\n\",\"  323 -> 110\\n\",\"  325 -> 111\\n\",\"  327 -> 112\\n\",\"  330 -> 113\\n\",\"  335 -> 114\\n\",\"  338 -> 115\\n\",\"  339 -> 116\\n\",\"  341 -> 117\\n\",\"  344 -> 118\\n\",\"  346 -> 119\\n\",\"  350 -> 120\\n\",\"  351 -> 121\\n\",\"  353 -> 122\\n\",\"  354 -> 123\\n\",\"  355 -> 124\\n\",\"  358 -> 125\\n\",\"  359 -> 126\\n\",\"  361 -> 127\\n\",\"  365 -> 128\\n\",\"  366 -> 129\\n\",\"  367 -> 130\\n\",\"  369 -> 131\\n\",\"  377 -> 132\\n\",\"  378 -> 133\\n\",\"  379 -> 134\\n\",\"  380 -> 135\\n\",\"  381 -> 136\\n\",\"  382 -> 137\\n\",\"  383 -> 138\\n\",\"  386 -> 139\\n\",\"  389 -> 140\\n\",\"  391 -> 141\\n\",\"  392 -> 142\\n\",\"  394 -> 143\\n\",\"  396 -> 144\\n\",\"  398 -> 145\\n\",\"  401 -> 146\\n\",\"  403 -> 147\\n\",\"  407 -> 148\\n\",\"  409 -> 149\\n\",\"  410 -> 150\\n\",\"  411 -> 151\\n\",\"  412 -> 152\\n\",\"  413 -> 153\\n\",\"  420 -> 154\\n\",\"  421 -> 155\\n\",\"  423 -> 156\\n\",\"  425 -> 157\\n\",\"  430 -> 158\\n\",\"  432 -> 159\\n\",\"  438 -> 160\\n\",\"  439 -> 161\\n\",\"  440 -> 162\\n\",\"  442 -> 163\\n\",\"  445 -> 164\\n\",\"  446 -> 165\\n\",\"  451 -> 166\\n\",\"  453 -> 167\\n\",\"  454 -> 168\\n\",\"  455 -> 169\\n\",\"  456 -> 170\\n\",\"  457 -> 171\\n\",\"  458 -> 172\\n\",\"  460 -> 173\\n\",\"  461 -> 174\\n\",\"  463 -> 175\\n\",\"  467 -> 176\\n\",\"  470 -> 177\\n\",\"  471 -> 178\\n\",\"  474 -> 179\\n\",\"  475 -> 180\\n\",\"  477 -> 181\\n\",\"  483 -> 182\\n\",\"  484 -> 183\\n\",\"  486 -> 184\\n\",\"  490 -> 185\\n\",\"  491 -> 186\\n\",\"  492 -> 187\\n\",\"  494 -> 188\\n\",\"  496 -> 189\\n\",\"  500 -> 190\\n\",\"  502 -> 191\\n\",\"  504 -> 192\\n\",\"  505 -> 193\\n\",\"  507 -> 194\\n\",\"  509 -> 195\\n\",\"  510 -> 196\\n\",\"  511 -> 197\\n\",\"  514 -> 198\\n\",\"  517 -> 199\\n\",\"  518 -> 200\\n\",\"  519 -> 201\\n\",\"  520 -> 202\\n\",\"  521 -> 203\\n\",\"  527 -> 204\\n\",\"  528 -> 205\\n\",\"  532 -> 206\\n\",\"  533 -> 207\\n\",\"  534 -> 208\\n\",\"  537 -> 209\\n\",\"  538 -> 210\\n\",\"  544 -> 211\\n\",\"  549 -> 212\\n\",\"  551 -> 213\\n\",\"  553 -> 214\\n\",\"  555 -> 215\\n\",\"  558 -> 216\\n\",\"  568 -> 217\\n\",\"  569 -> 218\\n\",\"  575 -> 219\\n\",\"  579 -> 220\\n\",\"  581 -> 221\\n\",\"  584 -> 222\\n\",\"  589 -> 223\\n\",\"  593 -> 224\\n\",\"  594 -> 225\\n\",\"  597 -> 226\\n\",\"  599 -> 227\\n\",\"  601 -> 228\\n\",\"  602 -> 229\\n\",\"  603 -> 230\\n\",\"  605 -> 231\\n\",\"  610 -> 232\\n\",\"  616 -> 233\\n\",\"  617 -> 234\\n\",\"  625 -> 235\\n\",\"  627 -> 236\\n\",\"  631 -> 237\\n\",\"  634 -> 238\\n\",\"  638 -> 239\\n\",\"  644 -> 240\\n\",\"  646 -> 241\\n\",\"  648 -> 242\\n\",\"  650 -> 243\\n\",\"  655 -> 244\\n\",\"  656 -> 245\\n\",\"  657 -> 246\\n\",\"  658 -> 247\\n\",\"  662 -> 248\\n\",\"  667 -> 249\\n\",\"  668 -> 250\\n\",\"  670 -> 251\\n\",\"  671 -> 252\\n\",\"  675 -> 253\\n\",\"  677 -> 254\\n\",\"  678 -> 255\\n\",\"  680 -> 256\\n\",\"  681 -> 257\\n\",\"  683 -> 258\\n\",\"  686 -> 259\\n\",\"  689 -> 260\\n\",\"  692 -> 261\\n\",\"  693 -> 262\\n\",\"  695 -> 263\\n\",\"  696 -> 264\\n\",\"  698 -> 265\\n\",\"  699 -> 266\\n\",\"  700 -> 267\\n\",\"  702 -> 268\\n\",\"  703 -> 269\\n\",\"  705 -> 270\\n\",\"  707 -> 271\\n\",\"  708 -> 272\\n\",\"  710 -> 273\\n\",\"  711 -> 274\\n\",\"  712 -> 275\\n\",\"  713 -> 276\\n\",\"  717 -> 277\\n\",\"  718 -> 278\\n\",\"  720 -> 279\\n\",\"  721 -> 280\\n\",\"  723 -> 281\\n\",\"  724 -> 282\\n\",\"  726 -> 283\\n\",\"  727 -> 284\\n\",\"  728 -> 285\\n\",\"  729 -> 286\\n\",\"  730 -> 287\\n\",\"  731 -> 288\\n\",\"  732 -> 289\\n\",\"  734 -> 290\\n\",\"  737 -> 291\\n\",\"  742 -> 292\\n\",\"  744 -> 293\\n\",\"  745 -> 294\\n\",\"  746 -> 295\\n\",\"  750 -> 296\\n\",\"  752 -> 297\\n\",\"  753 -> 298\\n\",\"  755 -> 299\\n\",\"  756 -> 300\\n\",\"  758 -> 301\\n\",\"  760 -> 302\\n\",\"  762 -> 303\\n\",\"  763 -> 304\\n\",\"  765 -> 305\\n\",\"  766 -> 306\\n\",\"  767 -> 307\\n\",\"  769 -> 308\\n\",\"  770 -> 309\\n\",\"  771 -> 310\\n\",\"  772 -> 311\\n\",\"  774 -> 312\\n\",\"  775 -> 313\\n\",\"  779 -> 314\\n\",\"  780 -> 315\\n\",\"  782 -> 316\\n\",\"  783 -> 317\\n\",\"  784 -> 318\\n\",\"  785 -> 319\\n\",\"  786 -> 320\\n\",\"  788 -> 321\\n\",\"  789 -> 322\\n\",\"  790 -> 323\\n\",\"  792 -> 324\\n\",\"  793 -> 325\\n\",\"  794 -> 326\\n\",\"  795 -> 327\\n\",\"  798 -> 328\\n\",\"  799 -> 329\\n\",\"  800 -> 330\\n\",\"  801 -> 331\\n\",\"  802 -> 332\\n\",\"  805 -> 333\\n\",\"  808 -> 334\\n\",\"  812 -> 335\\n\",\"  813 -> 336\\n\",\"  814 -> 337\\n\",\"  815 -> 338\\n\",\"  816 -> 339\\n\",\"  817 -> 340\\n\",\"  819 -> 341\\n\",\"  822 -> 342\\n\",\"  823 -> 343\\n\",\"  824 -> 344\\n\",\"  825 -> 345\\n\",\"  826 -> 346\\n\",\"  827 -> 347\\n\",\"  828 -> 348\\n\",\"  829 -> 349\\n\",\"  831 -> 350\\n\",\"  833 -> 351\\n\",\"  834 -> 352\\n\",\"  835 -> 353\\n\",\"  836 -> 354\\n\",\"  838 -> 355\\n\",\"  839 -> 356\\n\",\"  840 -> 357\\n\",\"  841 -> 358\\n\",\"  842 -> 359\\n\",\"  843 -> 360\\n\",\"  845 -> 361\\n\",\"  846 -> 362\\n\",\"  847 -> 363\\n\",\"  848 -> 364\\n\",\"  849 -> 365\\n\",\"  850 -> 366\\n\",\"  851 -> 367\\n\",\"  852 -> 368\\n\",\"  853 -> 369\\n\",\"  854 -> 370\\n\",\"  855 -> 371\\n\",\"  856 -> 372\\n\",\"  857 -> 373\\n\",\"  858 -> 374\\n\",\"  859 -> 375\\n\",\"  863 -> 376\\n\",\"  865 -> 377\\n\",\"  866 -> 378\\n\",\"  867 -> 379\\n\",\"  868 -> 380\\n\",\"  869 -> 381\\n\",\"  870 -> 382\\n\",\"  872 -> 383\\n\",\"  874 -> 384\\n\",\"  875 -> 385\\n\",\"  876 -> 386\\n\",\"  877 -> 387\\n\",\"  878 -> 388\\n\",\"  879 -> 389\\n\",\"  880 -> 390\\n\",\"  881 -> 391\\n\",\"  882 -> 392\\n\",\"  883 -> 393\\n\",\"  884 -> 394\\n\",\"  885 -> 395\\n\",\"  886 -> 396\\n\",\"  890 -> 397\\n\",\"  891 -> 398\\n\",\"  892 -> 399\\n\",\"  893 -> 400\\n\",\"  894 -> 401\\n\",\"  895 -> 402\\n\",\"  898 -> 403\\n\",\"  900 -> 404\\n\",\"  901 -> 405\\n\",\"  902 -> 406\\n\",\"  903 -> 407\\n\",\"  904 -> 408\\n\",\"  906 -> 409\\n\",\"  907 -> 410\\n\",\"  908 -> 411\\n\",\"  909 -> 412\\n\",\"  910 -> 413\\n\",\"  912 -> 414\\n\",\"  913 -> 415\\n\",\"  915 -> 416\\n\",\"  916 -> 417\\n\",\"  921 -> 418\\n\",\"  922 -> 419\\n\",\"  923 -> 420\\n\",\"  925 -> 421\\n\",\"  926 -> 422\\n\",\"  929 -> 423\\n\",\"  932 -> 424\\n\",\"  933 -> 425\\n\",\"  937 -> 426\\n\",\"  938 -> 427\\n\",\"  939 -> 428\\n\",\"  940 -> 429\\n\",\"  941 -> 430\\n\",\"  942 -> 431\\n\",\"  943 -> 432\\n\",\"  944 -> 433\\n\",\"  945 -> 434\\n\",\"  946 -> 435\\n\",\"  947 -> 436\\n\",\"  949 -> 437\\n\",\"  950 -> 438\\n\",\"  951 -> 439\\n\",\"  952 -> 440\\n\",\"  953 -> 441\\n\",\"  956 -> 442\\n\",\"  958 -> 443\\n\",\"  962 -> 444\\n\",\"  964 -> 445\\n\",\"  965 -> 446\\n\",\"  966 -> 447\\n\",\"  967 -> 448\\n\",\"  968 -> 449\\n\",\"  969 -> 450\\n\",\"  971 -> 451\\n\",\"  972 -> 452\\n\",\"  973 -> 453\\n\",\"  974 -> 454\\n\",\"  975 -> 455\\n\",\"  976 -> 456\\n\",\"  977 -> 457\\n\",\"  979 -> 458\\n\",\"  980 -> 459\\n\",\"  982 -> 460\\n\",\"  983 -> 461\\n\",\"  984 -> 462\\n\",\"  985 -> 463\\n\",\"  988 -> 464\\n\",\"  989 -> 465\\n\",\"  990 -> 466\\n\",\"  993 -> 467\\n\",\"  994 -> 468\\n\",\"  995 -> 469\\n\",\"  997 -> 470\\n\",\"  998 -> 471\\n\",\"  999 -> 472\\n\",\"  1000 -> 473\\n\",\"  1002 -> 474\\n\",\"  1008 -> 475\\n\",\"  1009 -> 476\\n\",\"  1010 -> 477\\n\",\"  1011 -> 478\\n\",\"  1015 -> 479\\n\",\"  1017 -> 480\\n\",\"  1019 -> 481\\n\",\"  1021 -> 482\\n\",\"  1025 -> 483\\n\",\"  1028 -> 484\\n\",\"  1032 -> 485\\n\",\"  1036 -> 486\\n\",\"  1038 -> 487\\n\",\"  1039 -> 488\\n\",\"  1040 -> 489\\n\",\"  1042 -> 490\\n\",\"  1043 -> 491\\n\",\"  1045 -> 492\\n\",\"  1046 -> 493\\n\",\"  1047 -> 494\\n\",\"  1048 -> 495\\n\",\"  1050 -> 496\\n\",\"  1051 -> 497\\n\",\"  1052 -> 498\\n\",\"  1054 -> 499\\n\",\"  1055 -> 500\\n\",\"  1056 -> 501\\n\",\"  1062 -> 502\\n\",\"  1063 -> 503\\n\",\"  1064 -> 504\\n\",\"  1071 -> 505\\n\",\"  1075 -> 506\\n\",\"  1076 -> 507\\n\",\"  1077 -> 508\\n\",\"  1078 -> 509\\n\",\"  1079 -> 510\\n\",\"  1080 -> 511\\n\",\"  1081 -> 512\\n\",\"  1082 -> 513\\n\",\"  1089 -> 514\\n\",\"  1090 -> 515\\n\",\"  1091 -> 516\\n\",\"  1092 -> 517\\n\",\"  1094 -> 518\\n\",\"  1095 -> 519\\n\",\"  1097 -> 520\\n\",\"  1101 -> 521\\n\",\"  1104 -> 522\\n\",\"  1105 -> 523\\n\",\"  1110 -> 524\\n\",\"  1111 -> 525\\n\",\"  1113 -> 526\\n\",\"  1117 -> 527\\n\",\"  1120 -> 528\\n\",\"  1122 -> 529\\n\",\"  1123 -> 530\\n\",\"  1125 -> 531\\n\",\"  1127 -> 532\\n\",\"  1128 -> 533\\n\",\"  1129 -> 534\\n\",\"  1131 -> 535\\n\",\"  1132 -> 536\\n\",\"  1133 -> 537\\n\",\"  1135 -> 538\\n\",\"  1138 -> 539\\n\",\"  1139 -> 540\\n\",\"  1140 -> 541\\n\",\"  1141 -> 542\\n\",\"  1143 -> 543\\n\",\"  1144 -> 544\\n\",\"  1146 -> 545\\n\",\"  1147 -> 546\\n\",\"  1150 -> 547\\n\",\"  1151 -> 548\\n\",\"  1152 -> 549\\n\",\"  1156 -> 550\\n\",\"  1159 -> 551\\n\",\"  1166 -> 552\\n\",\"  1168 -> 553\\n\",\"  1169 -> 554\\n\",\"  1172 -> 555\\n\",\"  1173 -> 556\\n\",\"  1177 -> 557\\n\",\"  1182 -> 558\\n\",\"  1185 -> 559\\n\",\"  1186 -> 560\\n\",\"  1193 -> 561\\n\",\"  1194 -> 562\\n\",\"  1195 -> 563\\n\",\"  1196 -> 564\\n\",\"  1199 -> 565\\n\",\"  1201 -> 566\\n\",\"  1202 -> 567\\n\",\"  1205 -> 568\\n\",\"  1206 -> 569\\n\",\"  1209 -> 570\\n\",\"  1211 -> 571\\n\",\"  1212 -> 572\\n\",\"  1213 -> 573\\n\",\"  1214 -> 574\\n\",\"  1215 -> 575\\n\",\"  1219 -> 576\\n\",\"  1220 -> 577\\n\",\"  1223 -> 578\\n\",\"  1224 -> 579\\n\",\"  1226 -> 580\\n\",\"  1227 -> 581\\n\",\"  1228 -> 582\\n\",\"  1229 -> 583\\n\",\"  1231 -> 584\\n\",\"  1233 -> 585\\n\",\"  1236 -> 586\\n\",\"  1237 -> 587\\n\",\"  1238 -> 588\\n\",\"  1241 -> 589\\n\",\"  1242 -> 590\\n\",\"  1243 -> 591\\n\",\"  1244 -> 592\\n\",\"  1245 -> 593\\n\",\"  1249 -> 594\\n\",\"  1255 -> 595\\n\",\"  1260 -> 596\\n\",\"  1264 -> 597\\n\",\"  1267 -> 598\\n\",\"  1271 -> 599\\n\",\"  1273 -> 600\\n\",\"  1274 -> 601\\n\",\"  1282 -> 602\\n\",\"  1285 -> 603\\n\",\"  1287 -> 604\\n\",\"  1294 -> 605\\n\",\"  1295 -> 606\\n\",\"  1302 -> 607\\n\",\"  1305 -> 608\\n\",\"\\n\",\"Step 3: Number of classes (including background): 609\\n\",\"\\n\",\"Step 4: Creating model...\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\\n\",\"  warnings.warn(\\n\",\"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\\n\",\"  warnings.warn(msg)\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"\\n\",\"Step 5: Creating datasets...\\n\",\"\\n\",\"Step 7: Setting up training...\\n\",\"Label mapping saved to label_mapping.pkl\\n\",\"\\n\",\"Setup complete!\\n\",\"- Original labels: [22, 23, 27, 28, 29, 46, 53, 55, 56, 57, 58, 61, 69, 86, 91, 98, 99, 100, 101, 102, 107, 109, 110, 112, 113, 116, 120, 122, 124, 128, 138, 142, 148, 150, 157, 161, 163, 164, 166, 167, 172, 175, 178, 180, 183, 185, 186, 187, 192, 198, 201, 203, 204, 206, 209, 212, 213, 218, 224, 229, 230, 233, 235, 236, 237, 239, 240, 241, 242, 243, 244, 247, 248, 249, 252, 253, 256, 257, 259, 260, 262, 264, 266, 267, 271, 273, 275, 278, 283, 284, 285, 288, 290, 291, 293, 294, 296, 297, 298, 302, 306, 307, 310, 311, 312, 314, 315, 316, 318, 323, 325, 327, 330, 335, 338, 339, 341, 344, 346, 350, 351, 353, 354, 355, 358, 359, 361, 365, 366, 367, 369, 377, 378, 379, 380, 381, 382, 383, 386, 389, 391, 392, 394, 396, 398, 401, 403, 407, 409, 410, 411, 412, 413, 420, 421, 423, 425, 430, 432, 438, 439, 440, 442, 445, 446, 451, 453, 454, 455, 456, 457, 458, 460, 461, 463, 467, 470, 471, 474, 475, 477, 483, 484, 486, 490, 491, 492, 494, 496, 500, 502, 504, 505, 507, 509, 510, 511, 514, 517, 518, 519, 520, 521, 527, 528, 532, 533, 534, 537, 538, 544, 549, 551, 553, 555, 558, 568, 569, 575, 579, 581, 584, 589, 593, 594, 597, 599, 601, 602, 603, 605, 610, 616, 617, 625, 627, 631, 634, 638, 644, 646, 648, 650, 655, 656, 657, 658, 662, 667, 668, 670, 671, 675, 677, 678, 680, 681, 683, 686, 689, 692, 693, 695, 696, 698, 699, 700, 702, 703, 705, 707, 708, 710, 711, 712, 713, 717, 718, 720, 721, 723, 724, 726, 727, 728, 729, 730, 731, 732, 734, 737, 742, 744, 745, 746, 750, 752, 753, 755, 756, 758, 760, 762, 763, 765, 766, 767, 769, 770, 771, 772, 774, 775, 779, 780, 782, 783, 784, 785, 786, 788, 789, 790, 792, 793, 794, 795, 798, 799, 800, 801, 802, 805, 808, 812, 813, 814, 815, 816, 817, 819, 822, 823, 824, 825, 826, 827, 828, 829, 831, 833, 834, 835, 836, 838, 839, 840, 841, 842, 843, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 863, 865, 866, 867, 868, 869, 870, 872, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 890, 891, 892, 893, 894, 895, 898, 900, 901, 902, 903, 904, 906, 907, 908, 909, 910, 912, 913, 915, 916, 921, 922, 923, 925, 926, 929, 932, 933, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 949, 950, 951, 952, 953, 956, 958, 962, 964, 965, 966, 967, 968, 969, 971, 972, 973, 974, 975, 976, 977, 979, 980, 982, 983, 984, 985, 988, 989, 990, 993, 994, 995, 997, 998, 999, 1000, 1002, 1008, 1009, 1010, 1011, 1015, 1017, 1019, 1021, 1025, 1028, 1032, 1036, 1038, 1039, 1040, 1042, 1043, 1045, 1046, 1047, 1048, 1050, 1051, 1052, 1054, 1055, 1056, 1062, 1063, 1064, 1071, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1089, 1090, 1091, 1092, 1094, 1095, 1097, 1101, 1104, 1105, 1110, 1111, 1113, 1117, 1120, 1122, 1123, 1125, 1127, 1128, 1129, 1131, 1132, 1133, 1135, 1138, 1139, 1140, 1141, 1143, 1144, 1146, 1147, 1150, 1151, 1152, 1156, 1159, 1166, 1168, 1169, 1172, 1173, 1177, 1182, 1185, 1186, 1193, 1194, 1195, 1196, 1199, 1201, 1202, 1205, 1206, 1209, 1211, 1212, 1213, 1214, 1215, 1219, 1220, 1223, 1224, 1226, 1227, 1228, 1229, 1231, 1233, 1236, 1237, 1238, 1241, 1242, 1243, 1244, 1245, 1249, 1255, 1260, 1264, 1267, 1271, 1273, 1274, 1282, 1285, 1287, 1294, 1295, 1302, 1305]\\n\",\"- Mapped labels: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608]\\n\",\"- Total classes (including background): 609\\n\",\"- Training samples: 506\\n\",\"- Test samples: 506\\n\",\"\\n\",\"Step 9: Testing data loader...\\n\",\"Warning: Key '00394.ppm' not found in annotations. Skipping...\\n\",\" Data loader working correctly!\\n\",\"  Batch size: 4\\n\",\"\\n\",\"You can now start training with:\\n\",\"- model: FasterRCNN\\n\",\"- data_loader: 127 batches\\n\",\"- data_loader_test: 506 batches\\n\",\"- device: cuda\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"from engine import train_one_epoch, evaluate\\n\",\"import utils\\n\",\"from IPython.display import clear_output\\n\",\"import pickle\\n\",\"import torch\\n\",\"import matplotlib.pyplot as plt\\n\",\"\\n\",\"# Set model to training mode\\n\",\"model.train()\\n\",\"\\n\",\"# Training configuration\\n\",\"num_epochs = 100\\n\",\"print_freq = 50\\n\",\"\\n\",\"# Initialize tracking lists\\n\",\"losses = []\\n\",\"loss_box_reg = []\\n\",\"loss_rpn_box_reg = []\\n\",\"loss_classifier = []\\n\",\"loss_objectness = []\\n\",\"\\n\",\"# COCO evaluation metrics\\n\",\"stat0 = []  # mAP @ IoU=0.50:0.95 | area=all | maxDets=100\\n\",\"stat1 = []  # mAP @ IoU=0.50 | area=all | maxDets=100\\n\",\"stat2 = []  # mAP @ IoU=0.75 | area=all | maxDets=100\\n\",\"stat3 = []  # mAP @ IoU=0.50:0.95 | area=small | maxDets=100\\n\",\"stat4 = []  # mAP @ IoU=0.50:0.95 | area=medium | maxDets=100\\n\",\"stat5 = []  # mAP @ IoU=0.50:0.95 | area=large | maxDets=100\\n\",\"stat6 = []  # mAR @ IoU=0.50:0.95 | area=all | maxDets=1\\n\",\"stat7 = []  # mAR @ IoU=0.50:0.95 | area=all | maxDets=10\\n\",\"stat8 = []  # mAR @ IoU=0.50:0.95 | area=all | maxDets=100\\n\",\"stat9 = []  # mAR @ IoU=0.50:0.95 | area=small | maxDets=100\\n\",\"stat10 = [] # mAR @ IoU=0.50:0.95 | area=medium | maxDets=100\\n\",\"stat11 = [] # mAR @ IoU=0.50:0.95 | area=large | maxDets=100\\n\",\"\\n\",\"print(f\\\"Starting training for {num_epochs} epochs...\\\")\\n\",\"print(f\\\"Device: {device}\\\")\\n\",\"print(f\\\"Model classes: {num_classes}\\\")\\n\",\"print(f\\\"Training batches: {len(data_loader)}\\\")\\n\",\"print(f\\\"Test batches: {len(data_loader_test)}\\\")\\n\",\"print(\\\"=\\\" * 50)\\n\",\"\\n\",\"for epoch in range(num_epochs):\\n\",\"    print(f\\\"\\\\nEpoch {epoch + 1}/{num_epochs}\\\")\\n\",\"\\n\",\"    # Training phase\\n\",\"    model.train()\\n\",\"    try:\\n\",\"        metrics = train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=print_freq)\\n\",\"\\n\",\"        # Extract training losses\\n\",\"        losses.append(float(str(metrics.meters['loss']).split(\\\" \\\")[0]))\\n\",\"        loss_box_reg.append(float(str(metrics.meters['loss_box_reg']).split(\\\" \\\")[0]))\\n\",\"        loss_rpn_box_reg.append(float(str(metrics.meters['loss_rpn_box_reg']).split(\\\" \\\")[0]))\\n\",\"        loss_classifier.append(float(str(metrics.meters['loss_classifier']).split(\\\" \\\")[0]))\\n\",\"        loss_objectness.append(float(str(metrics.meters['loss_objectness']).split(\\\" \\\")[0]))\\n\",\"\\n\",\"        print(f\\\"Training - Loss: {losses[-1]:.4f}, Box Reg: {loss_box_reg[-1]:.4f}, \\\"\\n\",\"              f\\\"Classifier: {loss_classifier[-1]:.4f}\\\")\\n\",\"\\n\",\"    except Exception as e:\\n\",\"        print(f\\\"Error during training: {e}\\\")\\n\",\"        break\\n\",\"\\n\",\"    # Update learning rate\\n\",\"    lr_scheduler.step()\\n\",\"    current_lr = optimizer.param_groups[0]['lr']\\n\",\"    print(f\\\"Learning Rate: {current_lr:.6f}\\\")\\n\",\"\\n\",\"    # Evaluation phase\\n\",\"    try:\\n\",\"        model.eval()\\n\",\"        coco_evaluator, metric_logger = evaluate(model, data_loader_test, device=device)\\n\",\"\\n\",\"        # Extract COCO evaluation stats\\n\",\"        stats = coco_evaluator.coco_eval['bbox'].stats\\n\",\"\\n\",\"        stat0.append(stats[0])   # mAP @ IoU=0.50:0.95\\n\",\"        stat1.append(stats[1])   # mAP @ IoU=0.50\\n\",\"        stat2.append(stats[2])   # mAP @ IoU=0.75\\n\",\"        stat3.append(stats[3])   # mAP small\\n\",\"        stat4.append(stats[4])   # mAP medium\\n\",\"        stat5.append(stats[5])   # mAP large\\n\",\"        stat6.append(stats[6])   # mAR @ maxDets=1\\n\",\"        stat7.append(stats[7])   # mAR @ maxDets=10\\n\",\"        stat8.append(stats[8])   # mAR @ maxDets=100\\n\",\"        stat9.append(stats[9])   # mAR small\\n\",\"        stat10.append(stats[10]) # mAR medium\\n\",\"        stat11.append(stats[11]) # mAR large\\n\",\"\\n\",\"        print(f\\\"Evaluation - mAP@0.5:0.95: {stat0[-1]:.4f}, mAP@0.5: {stat1[-1]:.4f}\\\")\\n\",\"\\n\",\"    except Exception as e:\\n\",\"        print(f\\\"Error during evaluation: {e}\\\")\\n\",\"        # Fill with zeros if evaluation fails\\n\",\"        for stat_list in [stat0, stat1, stat2, stat3, stat4, stat5, stat6, stat7, stat8, stat9, stat10, stat11]:\\n\",\"            stat_list.append(0.0)\\n\",\"\\n\",\"    # Save checkpoint every 10 epochs\\n\",\"    if (epoch + 1) % 10 == 0:\\n\",\"        checkpoint = {\\n\",\"            'epoch': epoch + 1,\\n\",\"            'model_state_dict': model.state_dict(),\\n\",\"            'optimizer_state_dict': optimizer.state_dict(),\\n\",\"            'scheduler_state_dict': lr_scheduler.state_dict(),\\n\",\"            'losses': losses,\\n\",\"            'mAP_50_95': stat0,\\n\",\"            'mAP_50': stat1,\\n\",\"            'label_mapping': label_mapping,\\n\",\"            'num_classes': num_classes\\n\",\"        }\\n\",\"        torch.save(checkpoint, f'checkpoint_epoch_{epoch + 1}.pth')\\n\",\"        print(f\\\"Checkpoint saved: checkpoint_epoch_{epoch + 1}.pth\\\")\\n\",\"\\n\",\"    # Plot progress every 20 epochs\\n\",\"    if (epoch + 1) % 20 == 0:\\n\",\"        plt.figure(figsize=(15, 5))\\n\",\"\\n\",\"        # Plot losses\\n\",\"        plt.subplot(1, 3, 1)\\n\",\"        plt.plot(losses, label='Total Loss')\\n\",\"        plt.plot(loss_classifier, label='Classifier Loss')\\n\",\"        plt.plot(loss_box_reg, label='Box Regression Loss')\\n\",\"        plt.title('Training Losses')\\n\",\"        plt.xlabel('Epoch')\\n\",\"        plt.ylabel('Loss')\\n\",\"        plt.legend()\\n\",\"        plt.grid(True)\\n\",\"\\n\",\"        # Plot mAP\\n\",\"        plt.subplot(1, 3, 2)\\n\",\"        plt.plot(stat0, label='mAP@0.5:0.95')\\n\",\"        plt.plot(stat1, label='mAP@0.5')\\n\",\"        plt.title('Mean Average Precision')\\n\",\"        plt.xlabel('Epoch')\\n\",\"        plt.ylabel('mAP')\\n\",\"        plt.legend()\\n\",\"        plt.grid(True)\\n\",\"\\n\",\"        # Plot learning rate\\n\",\"        plt.subplot(1, 3, 3)\\n\",\"        lrs = [losses[i] for i in range(len(losses))]  # You might want to track LR separately\\n\",\"        plt.plot(range(len(losses)), [current_lr] * len(losses))\\n\",\"        plt.title('Learning Rate')\\n\",\"        plt.xlabel('Epoch')\\n\",\"        plt.ylabel('LR')\\n\",\"        plt.grid(True)\\n\",\"\\n\",\"        plt.tight_layout()\\n\",\"        plt.savefig(f'training_progress_epoch_{epoch + 1}.png', dpi=150, bbox_inches='tight')\\n\",\"        plt.show()\\n\",\"\\n\",\"    print('-' * 50)\\n\",\"\\n\",\"    # Early stopping condition (optional)\\n\",\"    if len(stat0) > 50 and stat0[-1] < 0.001:  # If mAP is very low for too long\\n\",\"        print(\\\"Early stopping: mAP not improving\\\")\\n\",\"        break\\n\",\"\\n\",\"print(\\\"\\\\nTraining completed!\\\")\\n\",\"\\n\",\"# Save final results\\n\",\"final_results = {\\n\",\"    'losses': losses,\\n\",\"    'loss_box_reg': loss_box_reg,\\n\",\"    'loss_rpn_box_reg': loss_rpn_box_reg,\\n\",\"    'loss_classifier': loss_classifier,\\n\",\"    'loss_objectness': loss_objectness,\\n\",\"    'mAP_50_95': stat0,\\n\",\"    'mAP_50': stat1,\\n\",\"    'mAP_75': stat2,\\n\",\"    'mAP_small': stat3,\\n\",\"    'mAP_medium': stat4,\\n\",\"    'mAP_large': stat5,\\n\",\"    'mAR_1': stat6,\\n\",\"    'mAR_10': stat7,\\n\",\"    'mAR_100': stat8,\\n\",\"    'mAR_small': stat9,\\n\",\"    'mAR_medium': stat10,\\n\",\"    'mAR_large': stat11,\\n\",\"    'label_mapping': label_mapping,\\n\",\"    'reverse_mapping': reverse_mapping,\\n\",\"    'num_classes': num_classes,\\n\",\"    'total_epochs': len(losses)\\n\",\"}\\n\",\"\\n\",\"# Save results\\n\",\"with open('final_training_results.pkl', 'wb') as f:\\n\",\"    pickle.dump(final_results, f)\\n\",\"\\n\",\"# Save final model\\n\",\"torch.save({\\n\",\"    'model_state_dict': model.state_dict(),\\n\",\"    'label_mapping': label_mapping,\\n\",\"    'reverse_mapping': reverse_mapping,\\n\",\"    'num_classes': num_classes\\n\",\"}, 'final_model.pth')\\n\",\"\\n\",\"print(\\\"Results saved to:\\\")\\n\",\"print(\\\"- final_training_results.pkl\\\")\\n\",\"print(\\\"- final_model.pth\\\")\\n\",\"\\n\",\"# Print summary\\n\",\"if len(losses) > 0:\\n\",\"    print(f\\\"\\\\nTraining Summary:\\\")\\n\",\"    print(f\\\"Total epochs completed: {len(losses)}\\\")\\n\",\"    print(f\\\"Final loss: {losses[-1]:.4f}\\\")\\n\",\"    if len(stat0) > 0:\\n\",\"        print(f\\\"Final mAP@0.5:0.95: {stat0[-1]:.4f}\\\")\\n\",\"        print(f\\\"Final mAP@0.5: {stat1[-1]:.4f}\\\")\\n\",\"        print(f\\\"Best mAP@0.5:0.95: {max(stat0):.4f} (epoch {stat0.index(max(stat0)) + 1})\\\")\\n\",\"        print(f\\\"Best mAP@0.5: {max(stat1):.4f} (epoch {stat1.index(max(stat1)) + 1})\\\")\\n\",\"\\n\",\"print(\\\"\\\\nTraining finished successfully!\\\")\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"Wxt4o84Giry2\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1754218024043,\"user_tz\":-330,\"elapsed\":492,\"user\":{\"displayName\":\"Nikhil Guptha\",\"userId\":\"16060670023182016446\"}},\"outputId\":\"37d291f7-d83f-4561-fa62-26b9d8afcd39\"},\"execution_count\":34,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Starting training for 1000 epochs...\\n\",\"Device: cuda\\n\",\"Model classes: 609\\n\",\"Training batches: 127\\n\",\"Test batches: 506\\n\",\"==================================================\\n\",\"\\n\",\"Epoch 1/1000\\n\",\"Error during training: train_one_epoch() got an unexpected keyword argument 'print_freq'\\n\",\"\\n\",\"Training completed!\\n\",\"Results saved to:\\n\",\"- final_training_results.pkl\\n\",\"- final_model.pth\\n\",\"\\n\",\"Training finished successfully!\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"!grep -r \\\"def train_one_epoch\\\" /content/\\n\"],\"metadata\":{\"id\":\"bMiBT6NujULq\"},\"execution_count\":null,\"outputs\":[]}]}\n",
            "/content/drive/MyDrive/object_detect_gtsdb/engine.py:def train_one_epoch(model: torch.nn.Module, criterion: torch.nn.Module,\n"
          ]
        }
      ]
    }
  ]
}